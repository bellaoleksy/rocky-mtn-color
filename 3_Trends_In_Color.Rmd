---
title: "LimnoSat-US_Tutorial"
author: "Simon Topp"
date: "11/2/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---




```{r setup, include=FALSE}
library(tidyverse)
library(here)
library(leaflet)
library(sf)
library(feather)
library(lubridate)
library(mapview)
library(USAboundaries)
library(s2)
library(elevatr)
library(trend)
library(tsibble)
library(imputeTS)
library(ggthemes)
library(nhdplusTools)
library(tmap)
library(raster)
library(caret)
library(rpart)
library(yardstick)
library(rpart.plot)
library(patchwork)
library(cowplot)
library(lfstat) #for water_year function
library(zyp) #for zyp::zyp.sen, getting intercept for plotting sens slopes
# install.packages("remotes")
# remotes::install_github("MilesMcBain/breakerofchains")
library(breakerofchains)

# Use dplyr select
select<-dplyr::select

sf_use_s2(use_s2 = T)
knitr::opts_chunk$set(echo = TRUE, warning = F, comment = F, message = F)
```


## Trend Analysis

### Trend Data prep

Lots of key decisions in here. Could iterate


```{r, eval = F}



co_summary <- ls_co %>%
  dplyr::select(-year, -sat) %>%
  mutate(month = month(date),
         year = year(date),
         doy = yday(date)) %>%
  filter(month %in% 7:9, 
         doy <= 258) %>% #Sept 14/15
  group_by(Hylak_id,year) %>%
  add_count() %>%
  filter(year >= 1984) %>% #changed to >= so we don't drop 1984... 
  filter(n >= 3) %>% # at least 3 observations per year
  group_by(Hylak_id) %>%
  mutate(unique_years = n_distinct(year)) %>%
  filter(unique_years > 30) %>% # at least 30 years of data
  arrange(year) %>%
  #complete years
  group_by(Hylak_id,year) %>%
  summarize(across(c(Blue:dWL),
                   .fns = list(mean = mean,
                               sd = sd,
                               max = max,
                               min = min,
                               median = median), na.rm = T,
                   .names = "{.col}-{.fn}"))%>%
  ungroup() %>%
  as_tsibble(., key = Hylak_id, index=year) %>% #time series tibble
  fill_gaps() %>% #imputing, though not sure what's going on under the hood
  as_tibble() %>%
  pivot_longer(cols = `Blue-mean`:`dWL-median`,
               names_to = c('var','stat'),
               names_sep = '-') %>%
  group_by(Hylak_id, var, stat) %>%
  arrange(year) %>%
  mutate(impute_value = na_interpolation(value, maxgap = 1))


filled_enough <- co_summary %>%
  group_by(Hylak_id) %>%
  summarize(any_nas = any(is.na(impute_value))) %>% # check if there are missing values in each Hylak_id timeseries
  filter(any_nas == F) # only select the sites with a max of 1 year of missing data


co_full <- co_summary %>%
  filter(Hylak_id %in% filled_enough$Hylak_id) 

#How many lakes? 
length(unique(co_full$Hylak_id))

save(co_full, file = 'data/color_summary.RData')
```


## PRISM

#### Get lat/long for PRISM
```{r, eval=F}
#Extract lat/long for PRISM
dwl_all_ungrouped<-dwl_all%>%ungroup()%>%select(Hylak_id, geometry) 

separated_coord <- dwl_all_ungrouped %>%
    mutate(lat = unlist(map(dwl_all_ungrouped$geometry,2)),
           long = unlist(map(dwl_all_ungrouped$geometry,1))) %>%
  select(-geometry) %>%
  distinct() %>%
  relocate(Hylak_id, .after = last_col())

#PRISM can only pull 500 sites at a time, so split into two dataframes
separated_coord_1<-separated_coord %>%
  slice(1:500)
separated_coord_2<-separated_coord %>%
  slice(501:nrow(.))
# write_csv(separated_coord_1, "data/prism/separated_coord_1.csv", col_names = FALSE)
# write_csv(separated_coord_2, "data/prism/separated_coord_2.csv",col_names = FALSE)
# Use the above .csv files to download PRISM data for each individual lakes
# https://prism.oregonstate.edu/explorer/bulk.php 
```

#### Read in PRISM data
```{r}

dir<-here("data/prism/download")
files<-list.files(dir)
prism<-data.frame() # data frame to store all prism data
for(i in 1:length(files)){ # loops over all files in prism/download directory
  cur<-read.table(file.path(dir,paste(files[i],sep='')),
                  header=T,sep=",",skip=10,
                  stringsAsFactors = F) # read in all prism files
  cur$fileName<-files[i]
  #keep track of which .csv file data came from to make sure it's all there
  prism<-rbind(prism,cur)
}
prism<-prism %>%
    rename(ppt_mm=`ppt..mm.`,
           tmean_degC=`tmean..degrees.C.`,
           elev_m_prism=`Elevation..m.`,
           Hylak_id=Name,
           lon_dec_deg=Longitude,
           lat_dec_deg=Latitude,
           date=Date)%>%
  mutate(date=ym(date)) 


```

### Summary stats
```{r}


# Summary statistics by site
prism_sum <- prism %>%
  select(-c(lat_dec_deg, lon_dec_deg, elev_m_prism, fileName)) %>%
  pivot_longer(-c(Hylak_id, date)) %>%
  mutate(
    year = year(date),
    water_year = water_year(date, "usgs"),
    #uses the USGS standard of Oct
    month = month(date),
    season = case_when(
      year == water_year & month %in% c(3, 4, 5) ~ "spring",
      year == water_year &
        month %in% c(6, 7, 8) ~ "summer",
      year == water_year &
        month %in% c(1, 2) ~ "winter",
      year != water_year &
        month %in% c(12) ~ "winter"
    ),
    # Hylak_id=as.factor(as.integer(Hylak_id)),
    water_year = as.numeric(as.character(water_year))
  ) %>%
  drop_na(season) %>%
  group_by(Hylak_id, water_year, season, name) %>%
  summarize(mean = mean(value, na.rm = TRUE))

prism_sum_ppt <- prism_sum %>%
  filter(name == "ppt_mm")
prism_sum_temp <- prism_sum %>%
  filter(name == "tmean_degC")

##########################################################################################
##Functions for calculating sens slopes and intercepts for plotting later
##########################################################################################
map_sens2 <- function(df) {
  sens.slope(df$mean)
}


sens_slope <- function(mod) {
  mod$estimate[[1]]
}

#https://kevintshoemaker.github.io/NRES-746/TimeSeries_all.html
#For getting sens intercept, helpful for plotting later
map_zyp <- function(df) {
  zyp::zyp.sen(mean ~ water_year, df)
  # sens.slope(df$mean)
}


sens_intercept <- function(mod) {
  mod$coefficients[[1]] # pull out y-int estimate for ploting
}


#Coefficient of variation -- how variation is temp and precip over time?
cv <- function(df)  {
  sd(df$mean) / mean(df$mean)
}

## Precipitation first---
## Only keeping these separate for the trend categories.
prism_sum_ppt_nested <- prism_sum_ppt %>%
  group_by(Hylak_id, season, name) %>%
  nest() %>%
  mutate(
    sens = map(data, map_sens2),
    sens_sum = map(sens, broom::glance),
    slope = map(sens, sens_slope),
    zyp_mod = map(data, map_zyp),
    cv = map(data, cv),
    intercept = map(zyp_mod, sens_intercept)
  )

prism_sum_temp_nested <- prism_sum_temp %>%
  group_by(Hylak_id, season, name) %>%
  nest() %>%
  mutate(
    sens = map(data, map_sens2),
    sens_sum = map(sens, broom::glance),
    slope = map(sens, sens_slope),
    zyp_mod = map(data, map_zyp),
    cv = map(data, cv),
    intercept = map(zyp_mod, sens_intercept)
  )

## Un-nest PPT
prism_sum_ppt_unnested = unnest(prism_sum_ppt_nested, c(sens_sum, slope, season, name)) %>%
  mutate(
    Trend_ppt = case_when(
      p.value <= 0.05 & slope >= 0 ~ 'wetter',
      p.value <= 0.05 & slope <= 0 ~ 'drier',
      p.value > 0.05 ~ 'No trend'
    ),
    Trend_ppt = factor(Trend_ppt,
                       levels = c('No trend',
                                  'wetter',
                                  'drier'))
  )
## Un-nest TEMP
prism_sum_temp_unnested = unnest(prism_sum_temp_nested, c(sens_sum, slope, season, name)) %>%
  mutate(
    Trend_temp = case_when(
      p.value <= 0.05 & slope >= 0 ~ 'warmer',
      p.value <= 0.05 &
        slope <= 0 ~ 'cooler',
      p.value > 0.05 ~ 'No trend'
    ),
    Trend_temp = factor(Trend_temp,
                        levels = c('No trend',
                                   'warmer',
                                   'cooler'))
  )

#Extract all covariates for modeling...
prism_ppt_trends_wide <- prism_sum_ppt_unnested %>%
  select(Hylak_id, season, name, cv, slope) %>%
  unnest(c(cv, slope)) %>%
  pivot_wider(names_from = c("season", "name"),
              values_from = c("slope", "cv"))

prism_temp_trends_wide <- prism_sum_temp_unnested %>%
  select(Hylak_id, season, name, cv, slope) %>%
  unnest(c(cv, slope)) %>%
  pivot_wider(names_from = c("season", "name"),
              values_from = c("slope", "cv"))


##Dataframe with all the actual slopes and cv values
prism_trends_wide <-
  inner_join(prism_ppt_trends_wide, prism_temp_trends_wide)

##Data with all the ppt and temp trend categories
ppt_trend_categories <- prism_sum_ppt_unnested %>%
  select(Hylak_id, Trend_ppt) %>%
  pivot_wider(
    names_from = c("season"),
    values_from = c("Trend_ppt"),
    names_prefix = "ppt_trend_"
  ) %>%
  ungroup() %>%
  select(-name)

temp_trend_categories <- prism_sum_temp_unnested %>%
  select(Hylak_id, Trend_temp) %>%
  pivot_wider(
    names_from = c("season"),
    values_from = c("Trend_temp"),
    names_prefix = "temp_trend_"
  ) %>%
  ungroup() %>%
  select(-name)

prism_trend_categories <-
  inner_join(ppt_trend_categories, temp_trend_categories)
```

#### Interrogate trends
```{r}

#How many lakes are getting wetter/drier in each season?
prism_sum_ppt_unnested %>%
  unnest(data) %>%
  ungroup() %>%
  mutate(n_lakes_total = length(unique(Hylak_id))) %>%
  group_by(Trend_ppt, season, n_lakes_total) %>%
  summarize(n_trending = length(unique(Hylak_id))) %>%
  mutate(perc = (n_trending / sum(n_lakes_total)) * 100,
         perc = round(perc, 1))

#How many lakes are getting warmer/cooler in each season?
prism_sum_temp_unnested %>%
  unnest(data) %>%
  ungroup() %>%
  mutate(n_lakes_total = length(unique(Hylak_id))) %>%
  group_by(Trend_temp, season, n_lakes_total) %>%
  summarize(n_trending = length(unique(Hylak_id))) %>%
  mutate(perc = (n_trending / sum(n_lakes_total)) * 100,
         perc = round(perc, 1)) 

```

## Human populations trends
```{r}
load("data/glcp_sub.RData")
population_trends <-  glcp_high_lakes %>%
  select(Hylak_id, year, pop_sum) %>%
  drop_na() %>%
  pivot_wider(names_from = "year",
              values_from = "pop_sum",
              names_prefix = "pop_year_") %>%
  group_by(Hylak_id) %>%
  summarize(population_change = ((pop_year_2015 - pop_year_1995) / pop_year_1995) *
              100)

```


## Net Trends in DWL


```{r}

load('data/ls_elev.RData')
load('data/color_summary.RData')
load('data/nhd_lakes.RData')


nhd_hylak <- nhd_hylak %>%
  filter(elevation >= 1400) %>% ## changed to have the same cut off as in 2_GreenBlueMedians.Rmd?
  filter(ftype %in% c('LakePond', 'Reservoir'))

actually_high_lakes <- nhd_hylak


high_lakes <- co_full %>%
  filter(Hylak_id %in% actually_high_lakes$Hylak_id)

#How many lakes?
length(unique(high_lakes$Hylak_id))

map_sens <- function(df) {
  sens.slope(df$impute_value)
}


#https://kevintshoemaker.github.io/NRES-746/TimeSeries_all.html
#For getting sens intercept, helpful for plotting later
map_zyp <- function(df) {
  zyp::zyp.sen(impute_value ~ year, df)
}


sens_intercept <- function(mod) {
  mod$coefficients[[1]] # pull out y-int estimate for ploting
}


sens_est <- function(mod) {
  mod$estimates[[1]] #changed because others slope is a `named num` rather than numeric
  # mod$estimate
}

val_mean <- function(df) {
  early_mean <- df %>%
    filter(year < 2005) %>%
    pull(impute_value) %>%
    mean(., na.rm = T)
}

trend_plotter <- function(study_lakes = high_lakes,
                          v = 'dWL',
                          x = 'Dominant Wavelength Sens Slope') {
  trend_plot <- function(df) {
    ggplot(df, aes(x = year,
                   y = impute_value)) +
      geom_point() +
      stat_smooth(method = 'lm')
  }
  
  
  co_mods <- study_lakes %>%
    filter(var == v) %>%
    group_by(Hylak_id, stat) %>%
    nest() %>%
    mutate(
      sens = map(data, map_sens),
      plots = map(data, trend_plot),
      sens_sum = map(sens, broom::glance),
      slope = map(sens, sens_est),
      zyp_mod = map(data, map_zyp),
      intercept = map(zyp_mod, sens_intercept),
      early_mean = map(data, val_mean)
    )
  
  
  
  
  
  
  sens_sum = unnest(co_mods, c(sens_sum, slope, early_mean)) %>%
    mutate(
      Trend = case_when(
        p.value <= 0.05 & slope >= 0 & early_mean < 530 ~ 'Blue -> Green',
        p.value <= 0.05 &
          slope >= 0 &
          early_mean >= 530 ~ 'Intensifying Green/Yellow',
        #Added >= instead of > IAO 2022-01-25
        p.value <= 0.05 &
          slope <= 0 & early_mean > 530 ~ 'Green -> Blue',
        p.value <= 0.05 &
          slope <= 0 & early_mean < 530 ~ 'Intensifying Blue',
        p.value > 0.05 ~ 'No trend'
      ),
      Trend = factor(
        Trend,
        levels = c(
          'No trend',
          'Intensifying Blue',
          'Green -> Blue',
          'Intensifying Green/Yellow',
          'Blue -> Green'
        )
      )
    )
  
  
  plot <- ggplot(sens_sum %>%
                   dplyr::filter(stat != 'sd'),
                 aes(x = slope, color = Trend)) +
    geom_freqpoly(bins = 20, size = 1) +
    facet_wrap( ~ stat) +
    theme_few() +
    theme(legend.position = 'top',
          legend.direction = 'horizontal') +
    guides(color = guide_legend(nrow = 2, byrow = TRUE)) +
    scale_color_manual(
      values = c('gray20', '#1f78b4', '#a6cee3', '#b2df8a', '#33a02c'),
      name = ''
    ) +
    xlab(x) +
    ylab('Lake count')
  
  
  return(list(sens_sum, plot))
}
```

## DWL modes

### DWL histogram


```{r}
high_lakes_descriptor <- glcp_high_lakes %>%
  group_by(Hylak_id) %>%
  summarize(across(where(is.numeric),mean))

 

high_modes <- high_lakes %>%
  filter(var == 'dWL',
         stat == 'median') %>%
  dplyr::mutate(decade = cut(year, breaks = c(1984,1996,2008,2021),
                             labels = c('1985-96','1997-2008','2009-2020'))) %>%
  group_by(Hylak_id, decade) %>%
  summarize(dWL = round(median(value, na.rm = T),0)) %>%
  ungroup() %>%
  inner_join(fui.lookup) %>%
  inner_join(fui.colors) 


bg.fui = tibble(
  ymin = c(470,475,480,485,489,495,509,530,549,559,564,567,568,569,570,573,575,577,579,581,583),
  ymax = c(475,480,485,489,495,509,530,549,559,564,567,568,569,570,573,575,577,579,581,583,590),
  color = c(
  "#2158bc", "#316dc5", "#327cbb", "#4b80a0", "#568f96", "#6d9298", "#698c86", 
  "#759e72", "#7ba654", "#7dae38", "#94b660","#94b660", "#a5bc76", "#aab86d", 
  "#adb55f", "#a8a965", "#ae9f5c", "#b3a053", "#af8a44", "#a46905", "#9f4d04")
)

##Legend only
legend<-ggplot() + 
  geom_rect(data = bg.fui, 
            aes(ymin = ymin, ymax = ymax, xmin = -5, xmax = 100, fill = color)) + 
  scale_fill_identity() + 
  theme_few() +
  scale_x_continuous(expand = c(0, 0))+
  scale_y_continuous(expand = c(0, 0))+
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.y=element_text(size=5),
        axis.title.y=element_text(size=6),
        plot.title=element_text(size=6, hjust=-0.05))+
  labs(y="Dominant wavelength (nm)",
       title="Forel-Ule\ncolor")

# make prettier
# png(filename = 'figs/dwl_hist_three_periods.png', width = 4, height = 4,
#     units = 'in', res = 300)
# 
# 
# base<-ggplot() + 
#   facet_wrap(~decade, ncol = 1) + 
#   geom_rect(data = bg.fui, 
#             aes(xmin = ymin, xmax = ymax, ymin = -5, ymax = 100, fill = color)) + 
#   geom_vline(xintercept = 530, linetype = 3) +
#   geom_histogram(data = high_modes, aes(x=dWL, y = ..density..), fill = NA,
#                  color = 'black', alpha = .3, bins = 40) + 
#   geom_density(data = high_modes, aes(x=dWL)) + 
#   scale_x_continuous(expand = c(0, 0))+ #get rid of whitespace
#   scale_fill_identity() + 
#   theme_few() +
#   coord_cartesian(ylim = c(0,.03))  +
#   labs(x="Dominant wavelength (nm)",
#        y="Density")
# 
# base+inset_element(legend, 0.85, 0.75, 1, 1)
# 
# layout <- '
# A#
# AB
# A#
# '
# wrap_plots(A = base, B = legend, design = layout)+
#   plot_layout(widths = c(5, 0.5))
# 
# 
# dev.off()





```


## DWL Trends

```{r}
## Pull data for plotting
dWL_trends <- trend_plotter()


dwl <- dWL_trends[[1]] %>%
  inner_join(nhd_hylak, by = 'Hylak_id')

dwl_all <- dwl %>%
  filter(stat == 'median') %>%
  unnest(data) %>%
  unnest(intercept)


# set.seed(111)
# set.seed(1)
set.seed(999)
dwl_specials <- dwl_all %>%
  # filter(abs(slope) >= 1 | Trend == 'No trend') %>%
  # filter(p.value < 0.05 | Trend == 'No trend') %>% # Had to change from 0.001 to 0.05 to get a blue->green example lake
  filter(abs(slope) >= 1 &
           p.value < 0.05) %>% #I think it would be better to not show a trend line for "No Trend"
  group_by(Trend) %>%
  sample_n(1) %>%
  pull(Hylak_id)

full_spec <- dwl_all %>%
  filter(Hylak_id %in% dwl_specials)

#How many lakes in each trend category?
trend_labels <- dwl_all %>%
  group_by(Trend) %>%
  summarize(n = length(unique(Hylak_id))) %>%
  mutate(perc = (n / sum(n)) * 100,
         perc = round(perc, 0)) 



trendColors <- c(
  'No trend' = 'grey90',
  'Intensifying Blue' = '#1f78b4',
  'Green -> Blue' = '#a6cee3',
  'Intensifying Green/Yellow' = '#33a02c',
  'Blue -> Green' = '#b2df8a'
)


#Export
png(filename = 'figs/Trend Examples.png',
    width = 5,
    height = 8,
    res = 600,
    units = 'in')
ggplot(dwl_all, aes(x = year, y = value, group = Hylak_id)) +
  geom_abline(aes(intercept = intercept, slope = slope), color="grey50", size=0.1, alpha=0.5) + #background Sen's slopes
  geom_abline(data = full_spec, 
              aes(intercept = intercept, slope = slope, color=Trend),
              size=1) + #Sen's slope for selected sites
  geom_point(data = full_spec, aes(fill=Trend), shape=21) + 
  scale_fill_manual(values=trendColors)+
  scale_color_manual(values=trendColors)+
  geom_text(x = 1990, y = 585,
            aes(group=Trend, label = paste("n =",n)),
            color="black",
            data = trend_labels, size=3)+ #Add label for sample size
  scale_x_continuous(breaks=seq(1986, 2018, 6))+
  facet_wrap(~Trend, nrow=5) + 
  theme_few()+
  theme(legend.position="none",
        plot.margin = unit(c(0,0.2,0,0), "cm"),)+
  labs(y="Dominant wavelength (nm)",
       x="Year") +
  
  ggplot(dwl_all %>%
             distinct(Hylak_id,.keep_all = T),aes(x=slope,color=Trend)) + 
  geom_freqpoly(bins = 20, size = 1) + 
  geom_vline(xintercept=0, linetype="dashed", size=0.5)+
  facet_wrap(~Trend, nrow=5, scales="free_y") +
  theme_few() + 
  scale_y_continuous(position="right")+
  scale_x_continuous(breaks=seq(-1.5, 1.5, 1))+
  theme(legend.position="none",
        plot.margin = unit(c(0,0,0,0.2), "cm"),
        strip.text.x = element_text(color="white"), #Keep strips but color white so they are invisible
        legend.direction = 'horizontal') +
  scale_color_manual(values=trendColors)+
  xlab("Slope")+
  ylab('Lake count') + 
  plot_layout(widths = c(1, 0.6))
dev.off()

```

###~~ Stats for MS
```{r}

load('data/lakezones.RData')

#How many sites do we have in the spatial analysis?
length(unique(blue_green_2018$Hylak_id))
#956

#How many lakes in each spatial category?
blue_green_2018 %>%
  group_by(group) %>%
  count() %>%
  pivot_wider(names_from=group, values_from=n) %>%
  mutate(total=sum(`Blue/clear`,`Green/murky`),
         perc_blue=(`Blue/clear`/total)*100,
         perc_green=(`Green/murky`/total)*100)


#Is watershed slope correlated with WSA:LA?
cor.test(blue_green_2018$slope,
         log10(blue_green_2018$ws_area))
#Yes but pretty weakly, surprisingly
blue_green_2018 %>% 
  ggplot(aes(x=slope,y=log10(ws_area), fill=group, color=group))+
  geom_point(shape=21, color="black") +
  facet_wrap(~group, scales="free")+
  geom_smooth(method="lm")
#Pretty weird that you see opposite patterns between green & blue lakes...

#Is MAAT correlated with elevation?
cor.test(blue_green_2018$elev,
         blue_green_2018$air_temp)
A<-blue_green_2018 %>% 
  ggplot(aes(x=elev,y=air_temp, fill=group, color=group))+
  geom_point(shape=21, color="black") +
  # geom_hline(yintercept=4.5)+
  scale_fill_manual(values=c('#1f78b4','#33a02c'))+
  scale_color_manual(values=c('#1f78b4','#33a02c'))+
  theme_few()+
  geom_smooth(method="lm")+
  labs(y="MAAT ºC",
       x="Lake elevation (m)")

#Is watershed slope related to elevation?
blue_green_2018 %>% 
  ggplot(aes(x=elev,y=slope, fill=group, color=group))+
  geom_point(shape=21, color="black") +
  # facet_wrap(~group, scales="free")+
  geom_smooth(method="lm")
#Yes for green lakes but not for blue lakes... 

#Is watershed slope related to MAAT?
B<-blue_green_2018 %>% 
  ggplot(aes(x=air_temp,y=slope, fill=group, color=group))+
  geom_point(shape=21, color="black") +
  # facet_wrap(~group, scales="free")+
  geom_smooth(method="lm")+
  scale_fill_manual(values=c('#1f78b4','#33a02c'))+
  scale_color_manual(values=c('#1f78b4','#33a02c'))+
  theme_few()+
  labs(y="Watershed slope (degrees)",
       x="MAAT ºC")
cor.test(blue_green_2018$air_temp,
         blue_green_2018$slope)

#Is watershed slope related to % barren?
cor.test(blue_green_2018$perc_barren,
         blue_green_2018$slope)
C<-blue_green_2018 %>% 
  ggplot(aes(x=perc_barren,y=slope, fill=group, color=group))+
  geom_point(shape=21, color="black") +
  scale_fill_manual(values=c('#1f78b4','#33a02c'))+
  scale_color_manual(values=c('#1f78b4','#33a02c'))+
  # facet_wrap(~group, scales="free")+
  geom_smooth(method="lm")+
  theme_few()+
  labs(y="Watershed slope (degrees)",
       x="% barren")
#Yes

#Is watershed area related to MAAT?
cor.test(log10(blue_green_2018$pop_sum+.1),
         blue_green_2018$air_temp)
D<-blue_green_2018 %>% 
  ggplot(aes(x=pop_sum+.1,y=air_temp, fill=group, color=group))+
  geom_point(shape=21, color="black") +
  scale_fill_manual(values=c('#1f78b4','#33a02c'))+
  scale_color_manual(values=c('#1f78b4','#33a02c'))+
  scale_x_log10(labels = scales::label_number(),
                limits = c(1, 10000000))+
  geom_smooth(method="lm")+
  theme_few()+
  labs(y="MAAT ºC",
       x="Human populaton")

combined <- (A + D) / (B + C) & theme(legend.position = "bottom")
combined + plot_layout(guides = "collect") + plot_annotation(tag_levels = 'A')





#How many lakes in the temporal dataset?
length(unique(dwl_all$Hylak_id))

#How many lakes in each trend category?
dwl_all %>%
  group_by(Trend) %>%
  summarize(n = length(unique(Hylak_id))) %>%
  mutate(perc = (n / sum(n)) * 100,
         perc = round(perc, 0)) 


#How many of the intensifying green/yellow or blue->green lakes are reservoirs?
#How many lakes in each trend category?
dwl_all %>%  select(Hylak_id, Trend) %>%
  distinct(Hylak_id, .keep_all = T) %>%
  inner_join(blue_green_2018) %>% #add LakeCat variables
  ungroup() %>%
  group_by(Trend, res) %>%
  summarize(n = length(unique(Hylak_id))) %>%
  mutate(perc = (n / sum(n)) * 100,
         perc = round(perc, 0)) 

#Where are more of the green->blue lakes located?
dwl_all %>%
  ungroup() %>%
  inner_join(lake_descriptor %>% select(lagoslakeid, Hylak_id), by="Hylak_id") %>%
  inner_join(lakezones %>% select(lagoslakeid, lake_centroidstate), by="lagoslakeid") %>%
  distinct(Hylak_id,.keep_all = T) %>%
  group_by(Trend, lake_centroidstate) %>%
  summarize(n = length(unique(Hylak_id))) %>%
  mutate(perc = (n / sum(n)) * 100,
         perc = round(perc, 0)) %>%
  filter(Trend %in% c("Green -> Blue","Intensifying Blue"))

#What about blue->green
dwl_all %>%
  ungroup() %>%
  inner_join(lake_descriptor %>% select(lagoslakeid, Hylak_id), by="Hylak_id") %>%
  inner_join(lakezones %>% select(lagoslakeid, lake_centroidstate), by="lagoslakeid") %>%
  distinct(Hylak_id,.keep_all = T) %>%
  group_by(Trend, lake_centroidstate) %>%
  summarize(n = length(unique(Hylak_id))) %>%
  mutate(perc = (n / sum(n)) * 100,
         perc = round(perc, 0)) %>%
  filter(Trend %in% c("Blue -> Green","Intensifying Green/Yellow"))


#Look at ALL the lakes in the study region
lakezones_studyregion <- lakezones %>%
  filter(lake_centroidstate %in% c('CO','UT','WY','MT','NM','ID','NV')) %>%
  filter(lake_elevation_m >= 1400)

hist(log10(lakezones_studyregion$lake_totalarea_ha))

# How many of the lakes are >10 ha in surface area?
lakezones_studyregion %>%
  filter(lake_waterarea_ha >= 10) %>%
  count()

# What proportion of the large lakes did we capture in our trend analysis?
all_lakes_with_trend_lakes<-dwl_all %>%
  select(Hylak_id, Trend) %>%
  ungroup() %>%
  select(-stat) %>%
  distinct(Hylak_id, .keep_all = TRUE) %>%
  full_join(lake_descriptor %>%
               select(nhdplusv2_comid, Hylak_id, lagoslakeid, lake_lon_decdeg, lake_lat_decdeg)) %>%
  full_join(lakezones_studyregion %>%
              select(lagoslakeid, lake_namegnis, lake_waterarea_ha))

all_lakes_with_trend_lakes %>%
  filter(!is.na(Trend)) %>%
  count() / 
all_lakes_with_trend_lakes %>%
  filter(lake_waterarea_ha >= 10) %>%
  filter(is.na(Trend)) %>%
  count() 
#Approximately 25%

#What proportion of lakes in the regions are small (<10 ha) or large (>10 ha)
lakezones_studyregion <- lakezones_studyregion %>%
  mutate(
    size_class = case_when(
      lake_waterarea_ha <= 10 ~ 'small',
      TRUE ~ "large"
    )
  )
lakezones_studyregion %>%  
  group_by(size_class) %>%
  count()

#Ok, wow. So the proportion of total lakes that are large is:
2686/(2686+15568)
#Alternatively, the proportion of total lakes that are small is:
15568/(2686+15568)

#How those lakes are distributed by elevation
sp<-lakezones_studyregion %>%
  ggplot(aes(x=lake_waterarea_ha,y=lake_elevation_m,
            fill=size_class))+
  geom_point(shape=21,alpha=0.7)+
  scale_x_log10()+
  colorspace::scale_fill_discrete_qualitative(palette = "Dark 3")

# Marginal density plot of x (top panel) and y (right panel)
xplot <- ggdensity(lakezones_studyregion %>%
                     mutate(lake_waterarea_ha=log10(lake_waterarea_ha)), "lake_waterarea_ha", fill = "size_class")+
  colorspace::scale_fill_discrete_qualitative(palette = "Dark 3")
yplot <- ggdensity(lakezones_studyregion, "lake_elevation_m", fill = "size_class")+
  colorspace::scale_fill_discrete_qualitative(palette = "Dark 3")+
  rotate()
# Cleaning the plots
sp <- sp + rremove("legend")
yplot <- yplot + clean_theme() + rremove("legend") 
xplot <- xplot + clean_theme() + rremove("legend")
# Arranging the plot using cowplot
cowplot::plot_grid(xplot, NULL, sp, yplot, ncol = 2, align = "hv", 
      rel_widths = c(2, 1), rel_heights = c(1, 2))


### In the temporal analysis, what are the characteristics of lakes that are dropped due to missing data?
trends_df_inner<-dwl_all %>%
  ungroup()%>%
  inner_join(lake_descriptor %>% select(lagoslakeid, Hylak_id), by="Hylak_id") %>%
  inner_join(lakezones %>% select(lagoslakeid, lake_centroidstate), by="lagoslakeid") %>%
  select(Hylak_id, Trend) %>%
  distinct(Hylak_id,.keep_all = T) %>%
  inner_join(blue_green_2018) %>% #add LakeCat variables
  inner_join(prism_trends_wide) %>% #add PRISM variables
  inner_join(population_trends) %>% #add GLCP population variables
  inner_join(prism_trend_categories) %>%  #prism trend categories
  select(!contains("cv_")) %>%
  select(-dWL, -group, -precip, -air_temp, -area) %>%
  mutate(perc_agriculture=perc_ag+perc_hay) %>%
  select(-perc_ag, -perc_hay) %>%
  #Rename for plotting later
  rename("Human population"=pop_sum)
trends_df_left<-dwl_all %>%
  ungroup()%>%
  left_join(lake_descriptor %>% select(lagoslakeid, Hylak_id), by="Hylak_id") %>%
  left_join(lakezones %>% select(lagoslakeid, lake_centroidstate), by="lagoslakeid") %>%
  select(Hylak_id, Trend) %>%
  distinct(Hylak_id,.keep_all = T) %>%
  left_join(blue_green_2018) %>% #add LakeCat variables
  left_join(prism_trends_wide) %>% #add PRISM variables
  left_join(population_trends) %>% #add GLCP population variables
  left_join(prism_trend_categories) %>%  #prism trend categories
  select(!contains("cv_")) %>%
  select(-dWL, -group, -precip, -air_temp, -area) %>%
  mutate(perc_agriculture=perc_ag+perc_hay) %>%
  select(-perc_ag, -perc_hay) %>%
  #Rename for plotting later
  rename("Human population"=pop_sum)

dropped_set <- trends_df_left %>%
  filter(!Hylak_id %in% trends_df_inner$Hylak_id)

```

## DWL map

```{r}

load('data/spatial_data_analysis2.RData')

dwl_map <- dwl %>%
  filter(stat == 'median') %>%
  dplyr::select(Hylak_id,Trend) %>%
  inner_join(site_cols,.) %>%
  arrange(Trend)



png(filename = 'figs/trend_map.png',
    width = 4, height = 6, units = 'in', res = 300)

tm_shape(hil) +
  tm_raster(palette = gray(0:10 / 10), style = "cont", legend.show = FALSE) + 
tm_shape(ras) + 
  tm_raster(alpha = 0.2,
            style = 'cont',
            title = 'Elevation (m)',
            palette = 'Greys',
            legend.show = FALSE) + 
tm_shape(states) + 
  tm_borders(lwd = 1,
             col = 'black') + 
tm_shape(dwl_map) + 
    tm_bubbles(size = .2,
             col = 'Trend',
             shape=21,
             border.col = 'black',
             border.lwd = 1,
             alpha = 0.8,
             # jitter = .3,
             palette = c('gray20','#1f78b4','#a6cee3','#33a02c','#b2df8a')) +
tm_legend(legend.position = c(0,0),
            legend.bg.color = 'gray90',
            legend.frame = 'black') 
dev.off()

```

### DWL trend ridges
```{r}
library(ggridges)
png(filename = 'figs/trend_ridges.png',
    width = 2, height = 5.75, units = 'in', res = 300)
dwl_ridges <- dwl_all %>%
    filter(Trend!="No trend") %>%
  select(Hylak_id, value, Trend, year) %>%
  ungroup()

ggplot(dwl_ridges, aes(x = value, y = year, group = year)) +
  geom_density_ridges(
    data = filter(dwl_ridges, Trend == "Blue -> Green"),
    scale = 7,
    size = 0.25,
    rel_min_height = 0.01,
    fill = "#b2df8a",
    alpha = 0.4
  ) +
  geom_density_ridges(
    data = filter(dwl_ridges, Trend == "Green -> Blue"),
    scale = 7,
    size = 0.25,
    rel_min_height = 0.01,
    fill = "#a6cee3",
    alpha = 0.4
  ) +
  geom_density_ridges(
    data = filter(dwl_ridges, Trend == "Intensifying Blue"),
    scale = 7,
    size = 0.25,
    rel_min_height = 0.01,
    fill = "#1f78b4",
    alpha = 0.4
  ) +
  geom_density_ridges(
    data = filter(dwl_ridges, Trend == "Intensifying Green/Yellow"),
    scale = 7,
    size = 0.25,
    rel_min_height = 0.01,
    fill = "#33a02c",
    alpha = 0.4
  ) +
  theme_few(base_size = 9.5)+
  xlim(range(dwl_ridges$value)) + 
  facet_wrap( ~ Trend,nrow=4,scales="free_x")+
  theme(plot.margin = unit(c(0,0.1,0,0), "cm"))+
  scale_x_continuous(limits = c(470, 590), expand = c(0.01, 0)) +
  scale_y_reverse(breaks = c(seq(2020, 1984, -6))) +
  labs(x="Dominant wavelength (nm)",
       y="Year")
dev.off()

```


## DWL Trends -- why?

### (1) CART
```{r}

#Create df temporal modeling (will use the same df for RF and MLR)
trends_df<-dwl_all %>%
  ungroup()%>%
  inner_join(lake_descriptor %>% select(lagoslakeid, Hylak_id), by="Hylak_id") %>%
  inner_join(lakezones %>% select(lagoslakeid, lake_centroidstate, lake_elevation_m, lake_waterarea_ha), by="lagoslakeid") %>%
  select(Hylak_id, Trend) %>%
  distinct(Hylak_id,.keep_all = T) %>%
  # inner_join(blue_green_2018) %>% #add LakeCat variables
  inner_join(prism_trends_wide) %>% #add PRISM variables
  inner_join(population_trends) %>% #add GLCP population variables
  inner_join(prism_trend_categories) %>%  #prism trend categories
  select(!contains("cv_")) 
  # select(-dWL, -group, -precip, -air_temp, -area) %>%
  # mutate(perc_agriculture=perc_ag+perc_hay) %>%
  # select(-perc_ag, -perc_hay) %>%
  #Rename for plotting later
  # rename("Human population"=pop_sum)

set.seed(99)

trends_df %>%
  group_by(Trend) %>%
  summarize(n = length(unique(Hylak_id))) %>%
  mutate(perc = (n / sum(n)) * 100,
         perc = round(perc, 0)) 


##Method 1 - Add weights, e.g, give higher weight to smaller class
# train_d <- trends_df%>%
#   sample_frac(0.8)
# 
# test_d <- trends_df %>%
#   dplyr::filter(!Hylak_id %in% train_d$Hylak_id) %>%
#   select(-Hylak_id) %>%
#   mutate_if(is.numeric, round, digits=2) 
# 
# train_d <- train_d %>%
#   select(-Hylak_id) %>%
#   mutate_if(is.numeric, round, digits=2) 
# 
# 
# positiveWeight = 1.0 / (nrow(subset(train_d, Trend == "No trend")) / nrow(train_d))
# negativeWeight = 1.0 / (nrow(subset(train_d, Trend != "No trend")) / nrow(train_d))

# modelWeights <- ifelse(train_d$Trend == "No trend", positiveWeight, negativeWeight)

## Method 2 - Set aside a 25% of each trophic status group for validation
## Note: appears to give the same results as Method 1. 
val_ids <- trends_df %>% group_by(Trend) %>% slice_sample(prop=.25)
lakes <- trends_df %>% mutate(partition = ifelse(Hylak_id %in% val_ids$Hylak_id,'test','train'))

dplyr::count(lakes %>% ungroup(), Trend, partition)

## Set up our data partitoins
train_d = trends_df %>% filter(!Hylak_id %in% val_ids$Hylak_id) %>%  mutate_if(is.numeric, round, digits=2) 
test_d = trends_df %>% filter(Hylak_id %in% val_ids$Hylak_id) %>%  mutate_if(is.numeric, round, digits=2) 

## Models weights since the categories are so uneven
positiveWeight = 1.0 / (nrow(subset(train_d, Trend == "No trend")) / nrow(train_d))
negativeWeight = 1.0 / (nrow(subset(train_d, Trend != "No trend")) / nrow(train_d))
modelWeights <- ifelse(train_d$Trend == "No trend", positiveWeight, negativeWeight)


## Not run, but code that helped make decision about complexity parameter
# prune_mod <-caret::train(
#   Trend ~., data = train_d, method = "rpart",
#   trControl = trainControl("boot", number = 100),
#   tuneLength = 100,
#   weights = modelWeights
#   )


cart_mod <- rpart(Trend ~ ., data = train_d,
                  method = 'class',
                  weights = modelWeights,
                  cp = 0.053) # CP is a tuning knob for tree complexity.

test_d$guess <- predict(cart_mod, test_d, 'class')
cm <- conf_mat(test_d, Trend,guess)
accuracy(test_d,Trend,guess)

cart_pred <- as.data.frame(predict(cart_mod, test_d, type = 'prob'))
colnames(cart_pred) <- c("NT","BB","GB","GG","BG")
colnames(cart_pred) <- paste(colnames(cart_pred), "_pred_CART", sep="")



rpart.plot(cart_mod,
           type = 2, 
           extra = 2,
           under = TRUE, #
           clip.right.labs = FALSE,
           branch = 0.3,
           branch.col = "gray",
           main="Factors that influence lake category",
           box.palette = list('grey50','#1f78b4','#a6cee3','#33a02c','#b2df8a'))

## Pretty tree for publication
library(ggparty)

png(
  filename = 'figs/CART_temporal.png',
  width = 8,
  height = 8,
  res = 600,
  units = 'in'
)

cart_mod_party<-as.party(cart_mod)
temporal_tree_plot<-ggparty(cart_mod_party) +
  geom_edge(size=1, color="grey50") +
    # geom_node_label(aes(label = splitvar), ids = "inner") +
  geom_edge_label() +
  geom_node_splitvar() +
  geom_node_plot(gglist = list(geom_bar(aes(x = "", fill = Trend),
                                    position = position_fill()),#standardizes so each stack has constant height; plots proportions.
                               (scale_fill_manual(values=trendColors)),
                                                               (theme_few()),
                                # (scale_fill_manual(values=c('#b2df8a','#a6cee3'))),
                                #                                (theme_few()),
                               (theme(plot.margin = unit(c(0,0.2,0,0.2), "cm"),
                                axis.title.x=element_blank(),
                                axis.text.x=element_blank(),
                                axis.ticks.x=element_blank(),
                                legend.position="none")),
                               (scale_x_discrete(expand = c(0, 0))), #remove white space
                               # (scale_y_discrete(expand = c(0, 0))), #remove white space)
                               ylab("Proportion")),
                               shared_axis_labels = TRUE) +
    geom_node_label(aes(label = paste0("n=", nodesize)),
                  # fontface = "bold",
                  ids = "terminal",
                  size = 4, 
                  # nudge_y = 0.01,
                  nudge_x = 0.01)+
  theme(plot.margin = unit(c(0,0,0,0), "cm"))
temporal_tree_plot

dev.off()

##Confusion matrix base
## Manually create because the plot_confusion_matrix function isn't customizable enough for me
## Plot CART, RF, and MLR confusion matices all together a few chunks down. 
library(cvms)
conf_mat_CART <- confusion_matrix(targets = test_d$Trend,
                             predictions = test_d$guess)
tableCART<-data.frame(conf_mat_CART$`Confusion Matrix`)

plotTableCART <- tableCART %>%
  group_by(Target) %>%
  mutate(prop = N/sum(N),
         prop = round(prop,2))

plotTableCART$Match <- ifelse(plotTableCART$Prediction == plotTableCART$Target, 'Match',
                  ifelse(!plotTableCART$Prediction == plotTableCART$Target, 'No Match', 'Error'))




```

### (1b) CART with climate vars only
```{r}

sum(is.na(trends_df$meandepth))
sum(is.na(trends_df$maxdepth))

#Create df temporal modeling (will use the same df for RF and MLR)
trends_df<-dwl_all %>%
  ungroup()%>%
  left_join(lake_descriptor %>% select(lagoslakeid, Hylak_id), by="Hylak_id") %>%
  select(Hylak_id, Trend, meandepth, maxdepth) %>%
  distinct(Hylak_id,.keep_all = T) %>%
  left_join(prism_trends_wide) %>% #add PRISM variables
  left_join(prism_trend_categories) %>%  #prism trend categories
  select(!contains("cv_")) 
  # select(-dWL, -group, -precip, -air_temp, -area) %>%
  # mutate(perc_agriculture=perc_ag+perc_hay) %>%
  # select(-perc_ag, -perc_hay) %>%
  #Rename for plotting later
  # rename("Human population"=pop_sum)

set.seed(99)

trends_df<-dwl_all %>%
  ungroup()%>%
  left_join(lagos %>% select(lagoslakeid, Hylak_id, lake_maxdepth_m, lake_meandepth_m), by="Hylak_id") %>%
  select(Hylak_id, lagoslakeid,Trend, lake_maxdepth_m, lake_meandepth_m) %>%
  distinct(Hylak_id,.keep_all = T) %>%
  left_join(prism_trends_wide) %>% #add PRISM variables
  left_join(prism_trend_categories) %>%  #prism trend categories
  select(!contains("cv_")) 

sum(is.na(trends_df$lake_maxdepth_m))
sum(is.na(trends_df$lake_meandepth_m))

##Method 1 - Add weights, e.g, give higher weight to smaller class
# train_d <- trends_df%>%
#   sample_frac(0.8)
# 
# test_d <- trends_df %>%
#   dplyr::filter(!Hylak_id %in% train_d$Hylak_id) %>%
#   select(-Hylak_id) %>%
#   mutate_if(is.numeric, round, digits=2) 
# 
# train_d <- train_d %>%
#   select(-Hylak_id) %>%
#   mutate_if(is.numeric, round, digits=2) 
# 
# 
# positiveWeight = 1.0 / (nrow(subset(train_d, Trend == "No trend")) / nrow(train_d))
# negativeWeight = 1.0 / (nrow(subset(train_d, Trend != "No trend")) / nrow(train_d))

# modelWeights <- ifelse(train_d$Trend == "No trend", positiveWeight, negativeWeight)

## Method 2 - Set aside a 25% of each trophic status group for validation
## Note: appears to give the same results as Method 1. 
val_ids <- trends_df %>% group_by(Trend) %>% slice_sample(prop=.25)
lakes <- trends_df %>% mutate(partition = ifelse(Hylak_id %in% val_ids$Hylak_id,'test','train'))

dplyr::count(lakes %>% ungroup(), Trend, partition)

## Set up our data partitoins
train_d = trends_df %>% filter(!Hylak_id %in% val_ids$Hylak_id) %>%  mutate_if(is.numeric, round, digits=2) %>% select(-Hylak_id) 
test_d = trends_df %>% filter(Hylak_id %in% val_ids$Hylak_id) %>%  mutate_if(is.numeric, round, digits=2) %>% select(-Hylak_id)

## Models weights since the categories are so uneven
positiveWeight = 1.0 / (nrow(subset(train_d, Trend == "No trend")) / nrow(train_d))
negativeWeight = 1.0 / (nrow(subset(train_d, Trend != "No trend")) / nrow(train_d))
modelWeights <- ifelse(train_d$Trend == "No trend", positiveWeight, negativeWeight)


## Not run, but code that helped make decision about complexity parameter
prune_mod <-caret::train(
  Trend ~., data = train_d, method = "rpart",
  trControl = trainControl("boot", number = 100),
  tuneLength = 100,
  weights = modelWeights
  )


cart_mod <- rpart(Trend ~ ., data = train_d,
                  method = 'class',
                  weights = modelWeights,
                  cp = 0.018) # CP is a tuning knob for tree complexity.

test_d$guess <- predict(cart_mod, test_d, 'class')
cm <- conf_mat(test_d, Trend,guess)
accuracy(test_d,Trend,guess)

cart_pred <- as.data.frame(predict(cart_mod, test_d, type = 'prob'))
colnames(cart_pred) <- c("NT","BB","GB","GG","BG")
colnames(cart_pred) <- paste(colnames(cart_pred), "_pred_CART", sep="")



rpart.plot(cart_mod,
           type = 2, 
           extra = 2,
           under = TRUE, #
           clip.right.labs = FALSE,
           branch = 0.3,
           branch.col = "gray",
           main="Factors that influence trend category",
           box.palette = list('grey50','#1f78b4','#a6cee3','#33a02c','#b2df8a'))

## Pretty tree for publication
library(ggparty)

# png(
#   filename = 'figs/CART_temporal.png',
#   width = 8,
#   height = 8,
#   res = 600,
#   units = 'in'
# )

cart_mod_party<-as.party(cart_mod)
temporal_tree_plot<-ggparty(cart_mod_party) +
  geom_edge(size=1, color="grey50") +
    # geom_node_label(aes(label = splitvar), ids = "inner") +
  geom_edge_label() +
  geom_node_splitvar() +
  geom_node_plot(gglist = list(geom_bar(aes(x = "", fill = Trend),
                                    position = position_fill()),#standardizes so each stack has constant height; plots proportions.
                               (scale_fill_manual(values=trendColors)),
                                                               (theme_few()),
                                # (scale_fill_manual(values=c('#b2df8a','#a6cee3'))),
                                #                                (theme_few()),
                               (theme(plot.margin = unit(c(0,0.2,0,0.2), "cm"),
                                axis.title.x=element_blank(),
                                axis.text.x=element_blank(),
                                axis.ticks.x=element_blank(),
                                legend.position="none")),
                               (scale_x_discrete(expand = c(0, 0))), #remove white space
                               # (scale_y_discrete(expand = c(0, 0))), #remove white space)
                               ylab("Proportion")),
                               shared_axis_labels = TRUE) +
    geom_node_label(aes(label = paste0("n=", nodesize)),
                  # fontface = "bold",
                  ids = "terminal",
                  size = 4, 
                  # nudge_y = 0.01,
                  nudge_x = 0.01)+
  theme(plot.margin = unit(c(0,0,0,0), "cm"))
temporal_tree_plot

dev.off()

##Confusion matrix base
## Manually create because the plot_confusion_matrix function isn't customizable enough for me
## Plot CART, RF, and MLR confusion matices all together a few chunks down. 
library(cvms)
conf_mat_CART <- confusion_matrix(targets = test_d$Trend,
                             predictions = test_d$guess)
tableCART<-data.frame(conf_mat_CART$`Confusion Matrix`)

plotTableCART <- tableCART %>%
  group_by(Target) %>%
  mutate(prop = N/sum(N),
         prop = round(prop,2))

plotTableCART$Match <- ifelse(plotTableCART$Prediction == plotTableCART$Target, 'Match',
                  ifelse(!plotTableCART$Prediction == plotTableCART$Target, 'No Match', 'Error'))




```


### (2)  Random Forest
```{r}
library(randomForest)


# trends_df<-dwl_all %>%
#   ungroup()%>%
#   inner_join(lake_descriptor %>% select(lagoslakeid, Hylak_id), by="Hylak_id") %>%
#   inner_join(lakezones %>% select(lagoslakeid, lake_centroidstate), by="lagoslakeid") %>%
#   select(Hylak_id, Trend) %>%
#   distinct(Hylak_id,.keep_all = T) %>%
#   inner_join(blue_green_2018) %>% #add LakeCat variables
#   inner_join(prism_trends_wide) %>% #add PRISM variables
#   inner_join(population_trends) %>% #add GLCP population variables
#   inner_join(prism_trend_categories) %>%  #prism trend categories
#   select(!contains("cv_")) %>%
#   select(-dWL, -group, -precip, -air_temp, -area) %>%
#   mutate(perc_agriculture=perc_ag+perc_hay) %>%
#   select(-perc_ag, -perc_hay)

trends_df<-dwl_all %>%
  ungroup()%>%
  left_join(lake_descriptor %>% select(lagoslakeid, Hylak_id), by="Hylak_id") %>%
  left_join(lakezones %>% select(lagoslakeid, lake_centroidstate), by="lagoslakeid") %>%
  select(Hylak_id, Trend) %>%
  distinct(Hylak_id,.keep_all = T) %>%
  left_join(blue_green_2018) %>% #add LakeCat variables
  left_join(prism_trends_wide) %>% #add PRISM variables
  left_join(population_trends) %>% #add GLCP population variables
  left_join(prism_trend_categories) %>%  #prism trend categories
  select(!contains("cv_")) %>%
  select(-dWL, -group, -precip, -air_temp, -area) %>%
  mutate(perc_agriculture=perc_ag+perc_hay) %>%
  select(-perc_ag, -perc_hay)
set.seed(4444)


## Method 2 - Set aside a 25% of each trophic status group for validation
## Note: appears to give the same results as Method 1.
val_ids <- trends_df %>% group_by(Trend) %>% slice_sample(prop=.25)
lakes <- trends_df %>% mutate(partition = ifelse(Hylak_id %in% val_ids$Hylak_id,'test','train'))

dplyr::count(lakes %>% ungroup(), Trend, partition)

## Set up our data partitoins
train_d = trends_df %>% filter(!Hylak_id %in% val_ids$Hylak_id) %>%  mutate_if(is.numeric, round, digits=2)
test_d = trends_df %>% filter(Hylak_id %in% val_ids$Hylak_id) %>%  mutate_if(is.numeric, round, digits=2)



trControl <- trainControl(method = "cv",
    number = 10,
    search = "grid")

set.seed(1234)

#What the minimum number of samples in each category?
train_d %>%
  count(Trend) %>%
  summarize(min=min(n)) %>%
  pull()
  
## Another nice workflow for tuning the model is here: https://www.gmudatamining.com/lesson-13-r-tutorial.html
# Run the model
rf_default <- train(Trend~.,
    data = train_d,
    method = "rf",
    metric = "Accuracy",
    trControl = trControl,
    sampsize = rep(10, 5))
# Print the results
print(rf_default)

#Step 2) Search best mtry
tuneGrid <- expand.grid(.mtry = c(10: 20))
rf_mtry <- train(Trend~.,
    data = train_d,
    method = "rf",
    metric = "Accuracy",
    tuneGrid = tuneGrid,
    trControl = trControl,
    importance = TRUE,
    nodesize = 14,
    sampsize = rep(10, 5),
    ntree = 300)
print(rf_mtry)
rf_mtry$bestTune$mtry #best value
best_mtry <- rf_mtry$bestTune$mtry 
best_mtry

#3) search the best maxnodes

store_maxnode <- list()
tuneGrid <- expand.grid(.mtry = best_mtry)
for (maxnodes in c(5: 20)) {
    set.seed(1234)
    rf_maxnode <- train(Trend~.,
        data = train_d,
        method = "rf",
        metric = "Accuracy",
        tuneGrid = tuneGrid,
        trControl = trControl,
        importance = TRUE,
        nodesize = 14,
        sampsize = rep(10, 5),
        maxnodes = maxnodes,
        ntree = 300)
    current_iteration <- toString(maxnodes)
    store_maxnode[[current_iteration]] <- rf_maxnode
}
results_mtry <- resamples(store_maxnode)
summary(results_mtry)


#Step 4) Search the best ntrees
store_maxtrees <- list()
for (ntree in c(250, 300, 350, 400, 450, 500, 550, 600, 800, 1000, 2000)) {
    set.seed(5678)
    rf_maxtrees <- train(Trend~.,
        data = train_d,
        method = "rf",
        metric = "Accuracy",
        tuneGrid = tuneGrid,
        trControl = trControl,
        importance = TRUE,
        nodesize = 10,
        maxnodes = 7,
        sampsize = rep(10, 5),
        ntree = ntree)
    key <- toString(ntree)
    store_maxtrees[[key]] <- rf_maxtrees
}
results_tree <- resamples(store_maxtrees)
summary(results_tree)

#Use the previous model summaries to build the final model
fit_rf <- randomForest(Trend~.,
    train_d,
    method = "rf",
    metric = "Accuracy",
    tuneGrid = tuneGrid,
    trControl = trControl,
    importance = TRUE,
    nodesize = 10,
    ntree = 300,
    maxnodes = 7,
    sampsize = rep(15, 5))

# Step 5) Evaluate the model

prediction <-predict(fit_rf, test_d)
confMatRF<-confusionMatrix(prediction, test_d$Trend)
confMatRF

#Alt. way, same as how I made the CM for CART
test_d$guess <- predict(fit_rf, test_d, 'class')
conf_mat_RF <- confusion_matrix(targets = test_d$Trend,
                             predictions = test_d$guess)
tableRF<-data.frame(conf_mat_RF$`Confusion Matrix`)

plotTableRF <- tableRF %>%
  group_by(Target) %>%
  mutate(prop = N/sum(N),
         prop = round(prop,2))

plotTableRF$Match <- ifelse(plotTableRF$Prediction == plotTableRF$Target, 'Match',
                     ifelse(!plotTableRF$Prediction == plotTableRF$Target, 'No Match', 'Error'))




#Step 6) Visualize Result
varImpPlot(fit_rf)
imp_df<-importance(fit_rf)
imp_df

library(pdp)           # for partial dependence plots
library(vip)           # for variable importance plots
vip(fit_rf, geom = "col", horizontal = TRUE, size = 1.5, plot.engine="ggplot2") 
vip(fit_rf, bar = FALSE, horizontal = FALSE, size = 1.5)  


```

##### Distribution of top predictors

```{r}

png(
  filename = 'figs/RF_results.png',
  width = 8,
  height = 8,
  res = 600,
  units = 'in'
)


# A<-vip(fit_rf, geom = "col", num_features=5L, horizontal = FALSE, size = 1.5, plot.engine="ggplot2", include_type=TRUE) +
#   theme_few()

#Create plot from scratch so I can re-label the factors

A <- vi(fit_rf)[1:6, ] %>%
  mutate(
    Variable = replace(Variable, Variable %in% c("perc_agriculture"), "% Ag"),
    Variable = replace(Variable, Variable %in% c("cti"), "CTI"),
    Variable = replace(Variable, Variable %in% c("population_change"), "Pop. change"),
    Variable = replace(Variable, Variable %in% c("perc_forest"), "% Forest"),
    Variable = replace(Variable, Variable %in% c("elev"), "Elevation"),
    Variable = replace(Variable, Variable %in% c("perc_urban"), "% Urban"),
    Variable = replace(Variable, Variable %in% c("slope"), "Watershed slope"),
    Variable = replace(Variable, Variable %in% c("pop_sum"), "Human pop."),
    Variable = replace(Variable, Variable %in% c("slope_spring_tmean_degC"), "Slope of spring temp.")
  ) %>%
  ggplot(aes(
    y = Importance,
    x = forcats::fct_reorder(Variable, Importance, .desc = TRUE)
  )) +
  geom_bar(color="black",fill="grey50", width=0.75, position = "dodge", stat = "identity") +
  labs(y = "Importance\n(Mean Decr. Accuracy)") +
  theme_few() +
  theme(axis.title.x = element_blank(),
            axis.text.x = element_text(size=9))+
  scale_y_continuous(limits=c(0,6))


#Elevation
med_noTrend <-
  trends_df %>% filter(Trend == "No trend") %>% summarize(median(elev)) %>%
  pull()
B <-
  ggplot(trends_df, aes(x = Trend, y = elev, fill = Trend)) +
  # geom_violin()+
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(
    aes(fill = Trend),
    shape = 21,
    size = 0.5,
    alpha = 0.6,
    position = position_jitter(0.2)
  ) +
  geom_hline(yintercept = med_noTrend, linetype = "dashed") +
  scale_fill_manual(values = trendColors) +
  guides(fill = "none") +
  theme_few() +
  theme(
    axis.text.x = element_blank(),
    axis.title.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  labs(y = "Elevation (m)")

#% Urban
med_noTrend <-
  trends_df %>% filter(Trend == "No trend") %>% summarize(median(perc_urban+0.1)) %>%
  pull()
C <-ggplot(trends_df, aes(x = Trend, y = perc_urban+0.1, fill = Trend)) +
  # geom_violin()+
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(
    aes(fill = Trend),
    shape = 21,
    size = 0.5,
    alpha = 0.6,
    position = position_jitter(0.2)
  ) +
  geom_hline(yintercept = 0.1, linetype = "dashed") +
  scale_fill_manual(values = trendColors) +
  guides(fill = "none") +
  theme_few() +
  theme(
    axis.text.x = element_blank(),
    axis.title.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  scale_y_log10(labels = scales::label_number(),
                # expand = c(0,100),
                name = "% Urban")

#% Urban
#Consider logit transfomation as in Wagner & Schliep
med_noTrend <-
  trends_df %>% filter(Trend == "No trend") %>% summarize(median(perc_agriculture+0.1)) %>%
  pull()
D<-  ggplot(trends_df, aes(x = Trend, y = perc_agriculture+0.1, fill = Trend)) +
  # geom_violin()+
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(
    aes(fill = Trend),
    shape = 21,
    size = 0.5,
    alpha = 0.6,
    position = position_jitter(0.2)
  ) +
  geom_hline(yintercept = med_noTrend, linetype = "dashed") +
  scale_fill_manual(values = trendColors) +
  guides(fill = "none") +
  theme_few() +
  theme(
    axis.text.x = element_blank(),
    axis.title.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  scale_y_log10(labels = scales::label_number(),
                # expand = c(0,100),
                name = "% Agriculture")


# population change
med_noTrend <-
  trends_df %>% filter(Trend == "No trend") %>% summarize(median((population_change))) %>%
  pull()
E <- ggplot(trends_df, aes(x = Trend, y = population_change, fill = Trend)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(
    aes(fill = Trend),
    shape = 21,
    size = 0.5,
    alpha = 0.6,
    position = position_jitter(0.2)
  ) +
  geom_hline(yintercept = med_noTrend, linetype = "dashed") +
  # stat_summary(fun.min="quant.low",
  #              fun="median",
  #              fun.max="quant.high",
  #              geom="pointrange", shape = 5) +
  scale_fill_manual(values = trendColors) +
  guides(fill = "none") +
  theme_few() +
  theme(
    axis.text.x = element_blank(),
    axis.title.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  labs(y="% change in human population\nfrom 1995-2015")

#Human population
med_noTrend <-
  trends_df %>% filter(Trend == "No trend") %>% summarize(median(pop_sum+0.1)) %>%
  pull()
F<-  ggplot(trends_df, aes(x = Trend, y = pop_sum+0.1, fill = Trend)) +
  # geom_violin()+
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(
    aes(fill = Trend),
    shape = 21,
    size = 0.5,
    alpha = 0.6,
    position = position_jitter(0.2)
  ) +
  geom_hline(yintercept = (med_noTrend), linetype = "dashed") +
  scale_fill_manual(values = trendColors) +
  guides(fill = "none") +
  theme_few() +
  theme(
    axis.text.x = element_blank(),
    axis.title.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  scale_y_log10(labels = scales::label_number(),
                # expand = c(0,100),
                name = "Total human population")


#Spring temp slope
med_noTrend <-
  trends_df %>%
  filter(Trend == "No trend") %>%
  summarize(median((slope_spring_tmean_degC))) %>%
  pull()
G <- ggplot(trends_df, aes(x = Trend, y = slope_spring_tmean_degC, fill = Trend)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(
    aes(fill = Trend),
    shape = 21,
    size = 0.5,
    alpha = 0.6,
    position = position_jitter(0.2)
  ) +
  geom_hline(yintercept = med_noTrend, linetype = "dashed") +
  # stat_summary(fun.min="quant.low",
  #              fun="median",
  #              fun.max="quant.high",
  #              geom="pointrange", shape = 5) +
  scale_fill_manual(values = trendColors) +
  # guides(fill = "none") +
  theme_few() +
  theme(
    axis.text.x = element_blank(),
    axis.title.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  labs(y="Slope of spring temperature\n1984-2020 (deg C/year)")


layout <- "
AAAAAA
BBCCDD
EEFFGG
"


A + B + C + D + E + F + G +
  plot_annotation(tag_levels = 'A') +
  plot_layout(
    design = layout,
    guides = "collect",
    heights = c(0.4, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6)
  ) & theme(legend.position = 'bottom',
            legend.text = element_text(size=9))

dev.off()



```

```{r}
##KEEP AROUND - from early Feb

png(
  filename = 'figs/RF_results.png',
  width = 8,
  height = 8,
  res = 600,
  units = 'in'
)


# A<-vip(fit_rf, geom = "col", num_features=5L, horizontal = FALSE, size = 1.5, plot.engine="ggplot2", include_type=TRUE) +
#   theme_few()

#Create plot from scratch so I can re-label the factors

A <- vi(fit_rf)[1:6, ] %>%
  mutate(
    # Variable = replace(Variable, Variable %in% c("perc_agriculture"), "% Ag"),
    Variable = replace(Variable, Variable %in% c("perc_forest"), "% Forest"),
    Variable = replace(Variable, Variable %in% c("elev"), "Elevation"),
    Variable = replace(Variable, Variable %in% c("perc_urban"), "% Urban"),
    Variable = replace(Variable, Variable %in% c("slope"), "Watershed slope"),
    Variable = replace(Variable, Variable %in% c("pop_sum"), "Human population"),
    Variable = replace(Variable, Variable %in% c("slope_winter_ppt_mm"), "Slope of winter ppt.")
  ) %>%
  ggplot(aes(
    y = Importance,
    x = forcats::fct_reorder(Variable, Importance, .desc = TRUE)
  )) +
  geom_bar(color="black",fill="grey50", width=0.75, position = "dodge", stat = "identity") +
  labs(y = "Importance\n(Mean Decr. Accuracy)") +
  theme_few() +
  theme(axis.title.x = element_blank(),
            axis.text.x = element_text(size=9))+
  scale_y_continuous(limits=c(0,8))


#% Forest
med_noTrend <-
  trends_df %>% filter(Trend == "No trend") %>% summarize(median(slope)) %>%
  pull()
B <-
  ggplot(trends_df, aes(x = Trend, y = slope, fill = Trend)) +
  # geom_violin()+
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(
    aes(fill = Trend),
    shape = 21,
    size = 0.5,
    alpha = 0.6,
    position = position_jitter(0.2)
  ) +
  geom_hline(yintercept = med_noTrend, linetype = "dashed") +
  scale_fill_manual(values = trendColors) +
  guides(fill = "none") +
  theme_few() +
  theme(
    axis.text.x = element_blank(),
    axis.title.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  labs(y = "Watershed slope")

#Elevation
med_noTrend <-
  trends_df %>% filter(Trend == "No trend") %>% summarize(median(perc_urban+0.1)) %>%
  pull()
C <-ggplot(trends_df, aes(x = Trend, y = perc_urban+0.1, fill = Trend)) +
  # geom_violin()+
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(
    aes(fill = Trend),
    shape = 21,
    size = 0.5,
    alpha = 0.6,
    position = position_jitter(0.2)
  ) +
  geom_hline(yintercept = 0.1, linetype = "dashed") +
  scale_fill_manual(values = trendColors) +
  guides(fill = "none") +
  theme_few() +
  theme(
    axis.text.x = element_blank(),
    axis.title.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  scale_y_log10(labels = scales::label_number(),
                # expand = c(0,100),
                name = "% Urban")

#% Urban
#Consider logit transfomation as in Wagner & Schliep
med_noTrend <-
  trends_df %>% filter(Trend == "No trend") %>% summarize(median(slope_winter_ppt_mm)) %>%
  pull()
D<-  ggplot(trends_df, aes(x = Trend, y = slope_winter_ppt_mm, fill = Trend)) +
  # geom_violin()+
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(
    aes(fill = Trend),
    shape = 21,
    size = 0.5,
    alpha = 0.6,
    position = position_jitter(0.2)
  ) +
  geom_hline(yintercept = med_noTrend, linetype = "dashed") +
  scale_fill_manual(values = trendColors) +
  guides(fill = "none") +
  theme_few() +
  theme(
    axis.text.x = element_blank(),
    axis.title.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  labs(y="Slope of winter ppt. (mm/year)")
  # scale_y_log10(labels = scales::label_number(),
  #               # expand = c(0,100),
  #               name = "Slope of winter ppt. (mm/year)")


#Total population
med_noTrend <-
  trends_df %>% filter(Trend == "No trend") %>% summarize(median((pop_sum+1))) %>%
  pull()
E <- ggplot(trends_df, aes(x = Trend, y = pop_sum+1, fill = Trend)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(
    aes(fill = Trend),
    shape = 21,
    size = 0.5,
    alpha = 0.6,
    position = position_jitter(0.2)
  ) +
  geom_hline(yintercept = med_noTrend, linetype = "dashed") +
  # stat_summary(fun.min="quant.low",
  #              fun="median",
  #              fun.max="quant.high",
  #              geom="pointrange", shape = 5) +
  scale_fill_manual(values = trendColors) +
  guides(fill = "none") +
  theme_few() +
  theme(
    axis.text.x = element_blank(),
    axis.title.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  scale_y_log10(labels = scales::label_number_auto(),
                name = "Human population")

#Watershed slope
med_noTrend <-
  trends_df %>% filter(Trend == "No trend") %>% summarize(median(perc_forest)) %>%
  pull()
E<-  ggplot(trends_df, aes(x = Trend, y = perc_forest, fill = Trend)) +
  # geom_violin()+
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(
    aes(fill = Trend),
    shape = 21,
    size = 0.5,
    alpha = 0.6,
    position = position_jitter(0.2)
  ) +
  geom_hline(yintercept = (med_noTrend), linetype = "dashed") +
  scale_fill_manual(values = trendColors) +
  guides(fill = "none") +
  theme_few() +
  theme(
    axis.text.x = element_blank(),
    axis.title.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  labs(y="% Forest")
  # scale_y_log10(labels = scales::label_number(),
  #               # expand = c(0,100),
  #               name = "Watershed slope")



#CTI
med_noTrend <-
  trends_df %>%
  filter(Trend == "No trend") %>%
  summarize(median((LSA))) %>%
  pull()
G <- ggplot(trends_df, aes(x = Trend, y = LSA, fill = Trend)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(
    aes(fill = Trend),
    shape = 21,
    size = 0.5,
    alpha = 0.6,
    position = position_jitter(0.2)
  ) +
  geom_hline(yintercept = med_noTrend, linetype = "dashed") +
  # stat_summary(fun.min="quant.low",
  #              fun="median",
  #              fun.max="quant.high",
  #              geom="pointrange", shape = 5) +
  scale_fill_manual(values = trendColors) +
  # guides(fill = "none") +
  theme_few() +
  theme(
    axis.text.x = element_blank(),
    axis.title.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  labs(y="Lake surface\narea (km2)")+
  # scale_y_continuous(limits=c(500,1250))
  scale_y_log10(labels = scales::label_number(),
                # expand = c(0,100),
                name = "Lake surface area")


layout <- "
AAAAAA
BBCCDD
EEFFGG
"
A + B + C + D + E + F + G +
  plot_annotation(tag_levels = 'A') +
  plot_layout(
    design = layout,
    guides = "collect",
    heights = c(0.4, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6)
  ) & theme(legend.position = 'bottom',
            legend.text = element_text(size=9))

dev.off()





# #WTF is up with some of these winter temp trends?
# prism_sum_temp %>%
#   filter(Hylak_id %in% c("1059538","112241", #very negative
#                          "1059611","112167",#very positive
#                          "1062955")) %>% #reasonable
#   filter(name=="tmean_degC" & season=="winter") %>%
#   group_by(Hylak_id) %>%
#   mutate(sd=sd(mean+10, na.rm=T),
#             longmean=mean(mean+10, na.rm=T))%>%
#   ggplot(aes(x=water_year, y=mean))+
#   geom_point()+
#   geom_text(x = 1990, y = 4,
#             aes(group=Hylak_id, label = paste("sd =",round(sd,3))),
#             color="black", size=3)+ #Add label for sample size
#     geom_text(x = 1990, y = 3,
#             aes(group=Hylak_id, label = paste("mean =",round(longmean,3))),
#             color="black", size=3)+ #Add label for sample size
#   facet_wrap(~Hylak_id)

trendColors2 <- c(
  'No trend' = 'black',
  'Intensifying Blue' = '#1f78b4',
  'Green -> Blue' = '#a6cee3',
  'Intensifying Green/Yellow' = '#33a02c',
  'Blue -> Green' = '#b2df8a'
)

mu <- dwl_all %>%
  select(Hylak_id, Trend) %>%
  distinct(Hylak_id, .keep_all = T) %>%
  inner_join(blue_green_2018) %>% #add LakeCat variables
  inner_join(prism_trends_wide) %>% #add PRISM variables
  inner_join(population_trends) %>% #add GLCP population variables
  inner_join(prism_trend_categories) %>% #prism trend categories
  ungroup() %>%
  select(Trend,
         elev,
         cv_summer_tmean_degC,
         slope_spring_tmean_degC,
         slope) %>%
  pivot_longer(-Trend) %>%
  group_by(Trend, name) %>%
  summarize(grp.mean = mean(value, na.rm = TRUE))

dwl_all %>%
  select(Hylak_id, Trend) %>%
  distinct(Hylak_id, .keep_all = T) %>%
  inner_join(blue_green_2018) %>% #add LakeCat variables
  inner_join(prism_trends_wide) %>% #add PRISM variables
  inner_join(population_trends) %>% #add GLCP population variables
  inner_join(prism_trend_categories) %>% #prism trend categories
  ungroup() %>%
  select(Trend,
         elev,
         cv_summer_tmean_degC,
         slope_spring_tmean_degC,
         slope) %>%
  pivot_longer(-Trend) %>%
  ggplot(aes(x = value, group = Trend)) +
  geom_density(aes(fill = Trend), alpha = 0.4) +
  geom_vline(aes(xintercept = grp.mean, color = Trend),
             data = mu,
             linetype = "dashed") +
  scale_color_manual(values = trendColors2) +
  scale_fill_manual(values = trendColors) +
  # facet_wrap(name~., scales="free", nrow=5, ncol=4)
  facet_wrap(
    Trend ~ name,
    scales = "free",
    ncol = 4,
    strip.position = "right"
  )

#Elev plot
A<-dwl_all %>%
  select(Hylak_id, Trend) %>%
  distinct(Hylak_id, .keep_all = T) %>%
  inner_join(blue_green_2018) %>% #add LakeCat variables
  inner_join(prism_trends_wide) %>% #add PRISM variables
  inner_join(population_trends) %>% #add GLCP population variables
  inner_join(prism_trend_categories) %>% #prism trend categories
  ungroup() %>%
  select(Trend,
         elev,
         cv_summer_tmean_degC,
         slope_spring_tmean_degC,
         slope) %>%
  pivot_longer(-Trend) %>%
  filter(name=="elev")%>%
  ggplot(aes(x = value, group = Trend)) +
  # geom_density(aes(fill = Trend), alpha = 0.4) +
    geom_freqpoly(aes(color=Trend),bins = 10, size = 1) + 
  geom_vline(aes(xintercept = grp.mean, color = Trend),
             data = mu%>%
  filter(name=="elev"),
             linetype = "dashed") +
  scale_color_manual(values = trendColors2) +
  scale_fill_manual(values = trendColors) +
  facet_wrap(
    Trend ~ .,
    scales = "free_y",
    ncol = 1,
    strip.position = "right"
  )+
    theme_few()+
  theme(strip.text = element_blank(),
        legend.position = "none")+
  labs(x="Elevation (m)")
#cv_summer_tmean_degC plot
B<-dwl_all %>%
  select(Hylak_id, Trend) %>%
  distinct(Hylak_id, .keep_all = T) %>%
  inner_join(blue_green_2018) %>% #add LakeCat variables
  inner_join(prism_trends_wide) %>% #add PRISM variables
  inner_join(population_trends) %>% #add GLCP population variables
  inner_join(prism_trend_categories) %>% #prism trend categories
  ungroup() %>%
  select(Trend,cv_summer_tmean_degC) %>%
  pivot_longer(-Trend) %>%
  ggplot(aes(x = value, group = Trend)) +
  # geom_density(aes(fill = Trend), alpha = 0.4) +
    geom_freqpoly(aes(color=Trend),bins = 10, size = 1) + 
  geom_vline(aes(xintercept = grp.mean, color = Trend),
             data = mu%>%
  filter(name=="cv_summer_tmean_degC"),
             linetype = "dashed") +
  scale_color_manual(values = trendColors2) +
  scale_fill_manual(values = trendColors) +
  facet_wrap(
    Trend ~ .,
    scales = "free_y",
    ncol = 1,
    strip.position = "right"
  )+
  theme_few()+
  theme(strip.text = element_blank(),
        legend.position = "none")+
  labs(x="C.V. summer\ntemp (°C)")
#slope_spring_tmean_degC plot
C<-dwl_all %>%
  select(Hylak_id, Trend) %>%
  distinct(Hylak_id, .keep_all = T) %>%
  inner_join(blue_green_2018) %>% #add LakeCat variables
  inner_join(prism_trends_wide) %>% #add PRISM variables
  inner_join(population_trends) %>% #add GLCP population variables
  inner_join(prism_trend_categories) %>% #prism trend categories
  ungroup() %>%
  select(Trend,slope_spring_tmean_degC) %>%
  pivot_longer(-Trend) %>%
  ggplot(aes(x = value, group = Trend)) +
  # geom_density(aes(fill = Trend), alpha = 0.4) +
    geom_freqpoly(aes(color=Trend),bins = 10, size = 1) + 
  geom_vline(aes(xintercept = grp.mean, color = Trend),
             data = mu%>%
  filter(name=="slope_spring_tmean_degC"),
             linetype = "dashed") +
  scale_color_manual(values = trendColors2) +
  scale_fill_manual(values = trendColors) +
  facet_wrap(
    Trend ~ .,
    scales = "free_y",
    ncol = 1,
    strip.position = "right"
  )+
  theme_few()+
  theme(strip.text = element_blank(),
        legend.position = "none")+
  labs(x="Slope \nspring temp (°C)")
#slope_spring_tmean_degC plot
D<-dwl_all %>%
  select(Hylak_id, Trend) %>%
  distinct(Hylak_id, .keep_all = T) %>%
  inner_join(blue_green_2018) %>% #add LakeCat variables
  inner_join(prism_trends_wide) %>% #add PRISM variables
  inner_join(population_trends) %>% #add GLCP population variables
  inner_join(prism_trend_categories) %>% #prism trend categories
  ungroup() %>%
  select(Trend,slope) %>%
  pivot_longer(-Trend) %>%
  ggplot(aes(x = value, group = Trend)) +
  # geom_density(aes(fill = Trend), alpha = 0.4) +
  geom_freqpoly(aes(color=Trend),bins = 10, size = 1) + 
  geom_vline(aes(xintercept = grp.mean, color = Trend),
             data = mu%>%
  filter(name=="slope"),
             linetype = "dashed") +
  scale_color_manual(values = trendColors2) +
  scale_fill_manual(values = trendColors) +
  facet_wrap(
    Trend ~ .,
    scales = "free_y",
    ncol = 1,
    strip.position = "right"
  )+
  theme_few()+
  theme(legend.position = "none")+
  labs(x="Mean WS slope")
A|B|C|D 


```

### (3) Multinomial logistic regression

```{r}

## Models weights since the categories are so uneven
positiveWeight = 1.0 / (nrow(subset(train_d, Trend == "No trend")) / nrow(train_d))
negativeWeight = 1.0 / (nrow(subset(train_d, Trend != "No trend")) / nrow(train_d))
modelWeights <- ifelse(train_d$Trend == "No trend", positiveWeight, negativeWeight)




mn_res <- nnet::multinom(Trend ~  elev + perc_urban + perc_agriculture + population_change + pop_sum + slope_spring_tmean_degC,
                         data = train_d,
                         weights = modelWeights)
summary(mn_res)
mn_pred <- data.frame(predict(mn_res, test_d, type = 'prob'))
# mn_pred <- data.frame(mn_pred)
colnames(mn_pred) <- c("NT","BB","GB","GG","BG")
colnames(mn_pred) <- paste(colnames(mn_pred), "_pred_MN", sep="")

#Just like binary logistic regression, we need to convert the coefficients to odds by taking the exponential of the coefficients.
exp(coef(mn_res))

#Top 6 observations
head(round(fitted(mn_res), 2))

#Predicting and validating the model
# Predicting the values for train dataset
train_d$TrendPredicted <- predict(mn_res, newdata = train_d, "class")
# Building classification table
tab <- table(train_d$Trend, train_d$TrendPredicted)
# Calculating accuracy - sum of diagonal elements divided by total obs
round((sum(diag(tab))/sum(tab))*100,2)
# Output
# 62.8%


#Alt. way, same as how I made the CM for CART
test_d$guess <- predict(mn_res, test_d, 'class')
conf_mat_MLR <- confusion_matrix(targets = test_d$Trend,
                             predictions = test_d$guess)
tableMLR<-data.frame(conf_mat_MLR$`Confusion Matrix`)

plotTableMLR <- tableMLR %>%
  group_by(Target) %>%
  mutate(prop = N/sum(N),
         prop = round(prop,2))

plotTableMLR$Match <- ifelse(plotTableMLR$Prediction == plotTableMLR$Target, 'Match',
                     ifelse(!plotTableMLR$Prediction == plotTableMLR$Target, 'No Match', 'Error'))

```

#### ROC curves
```{r}

##### ROC curves
#https://github.com/WandeRum/multiROC
# install.packages('multiROC')
require(multiROC)

true_label <- data.frame(dummies::dummy(test_d$Trend))
colnames(true_label) <- c("NT","BB","GB","GG","BG")
colnames(true_label) <- paste(colnames(true_label), "_true", sep="")

rf_pred <- as.data.frame(predict(fit_rf, test_d, type = 'prob'))
colnames(rf_pred) <- c("NT","BB","GB","GG","BG")
colnames(rf_pred) <- paste(colnames(rf_pred), "_pred_RF", sep="")


final_df <- cbind(true_label, rf_pred)

roc_res <- multi_roc(final_df, force_diag=T)
pr_res <- multi_pr(final_df, force_diag=T)


plot_roc_df <- plot_roc_data(roc_res)
# plot_pr_df <- plot_pr_data(pr_res)

# ggplot(plot_roc_df, aes(x = 1-Specificity, y=Sensitivity)) +
#   geom_path(aes(color = Group), size=1.5) +
#   geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1), 
#                         colour='grey', linetype = 'dotdash') +
#   theme_few() + 
#   theme(plot.title = element_text(hjust = 0.5), 
#                  legend.justification=c(1, 0), legend.position=c(.95, .05),
#                  legend.title=element_blank(), 
#                  legend.background = element_rect(fill=NULL, size=0.5, 
#                                                            linetype="solid", colour ="black"))
# 
# ggplot(plot_pr_df, aes(x=Recall, y=Precision)) + 
#   geom_path(aes(color = Group, linetype=Method), size=1.5) + 
#   theme_bw() + 
#   theme(plot.title = element_text(hjust = 0.5), 
#                  legend.justification=c(1, 0), legend.position=c(.95, .05),
#                  legend.title=element_blank(), 
#                  legend.background = element_rect(fill=NULL, size=0.5, 
#                                                            linetype="solid", colour ="black"))
# 



#Compare with RF
final_df <- cbind(true_label, rf_pred, mn_pred, cart_pred)

roc_res <- multi_roc(final_df, force_diag=T)
pr_res <- multi_pr(final_df, force_diag=T)


plot_roc_df <- plot_roc_data(roc_res)
plot_pr_df <- plot_pr_data(pr_res)


trendColors3 <- c(
  'No trend' = 'grey50',
  'Intensifying Blue' = '#1f78b4',
  'Green -> Blue' = '#a6cee3',
  'Intensifying Green/Yellow' = '#33a02c',
  'Blue -> Green' = '#b2df8a',
  'Macro' ="#000000",
  'Micro' ="grey40"
)


png(
  filename = 'figs/ROC_comparison.png',
  width = 8,
  height = 8,
  res = 600,
  units = 'in'
)


plot_roc_df %>%
  mutate(Group = factor(
    Group,
    levels = c("NT", "BB", "GB", "GG", "BG", "Macro", "Micro"),
    labels = c(
      "No trend",
      'Intensifying Blue',
      'Green -> Blue',
      'Intensifying Green/Yellow',
      'Blue -> Green',
      "Macro",
      "Micro"
    )
  )) %>%
  ggplot(aes(x = 1 - Specificity, y = Sensitivity)) +
  geom_path(aes(color = Group, linetype = Method), size = 1.5) +
  geom_segment(aes(
    x = 0,
    y = 0,
    xend = 1,
    yend = 1
  ),
  colour = 'grey',
  linetype = 'dotdash') +
  theme_few() +
  scale_linetype_manual(values=c("solid","dotted","dashed"))+
  scale_color_manual(values = trendColors3) +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.justification = c(1, 0.1),
    legend.position = c(1, 0),
    legend.key.width = unit(4,"line"),
    legend.box = "horizontal",
    legend.background = element_rect(
      fill = NULL,
      size = 0.5,
      linetype = "solid",
      colour = "black"
    )
  ) +
  facet_wrap(. ~ Group)
dev.off()


#I think the above plot is preferable, but here is an alternative way:

plot_roc_df %>%
  # filter(Group %in% c("NT","BB","GB","GG","BG")) %>%
  mutate(Group=factor(Group,
                      levels=c("NT","BB","GB","GG","BG","Macro","Micro"),
                      labels = c("No trend",'Intensifying Blue','Green -> Blue','Intensifying Green/Yellow','Blue -> Green',"Macro","Micro"))) %>%
ggplot(aes(x = 1-Specificity, y=Sensitivity)) +
  geom_path(aes(color = Group, linetype=Group), size=1.5) +
  geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1), 
                        colour='grey', linetype = 'dotdash') +
  theme_few() + 
  scale_color_manual(values=trendColors3)+
  scale_linetype_manual(values=c("solid","solid","solid","solid","solid",
                                "dotdash","dotted"))+
  theme(plot.title = element_text(hjust = 0.5), 
                 legend.justification=c(1, 0), legend.position=c(1, 0),
                 legend.title=element_blank(), 
                 legend.background = element_rect(fill=NULL, size=0.5, 
                                                           linetype="solid", colour ="black"))+
  facet_wrap(.~Method)

```


#### Confusion matrices
```{r}


png(filename = 'figs/Confusion_matrices.png',
    width = 10, height = 5,
    units = 'in', res = 300)
ggplot(data = plotTableCART,
       mapping = aes(x = Target, y = Prediction)) +
  geom_tile(aes(fill=Match), color="black") +
  scale_x_discrete(expand = c(0, 0))+ #remove white space
  scale_y_discrete(expand = c(0, 0))+ #remove white space
  geom_text(aes(label = paste0("n=",N)), vjust = .5,  alpha = 1, size=3) +
  geom_text(aes(label = paste0("prop.=",prop)), vjust = 2.0,  alpha = 1, size=2) +
  scale_fill_manual(values = c('Match' = "#33a02c", 'No Match' = "white")) +
  theme_few() +
  theme(legend.position="none",
        axis.title.x=element_blank(),
        axis.text.x = element_text(
        angle = 45,
        hjust = 1,
        size = 8
      ))+
  labs(title="CART") +

ggplot(data = plotTableRF,
       mapping = aes(x = Target, y = Prediction)) +
  geom_tile(aes(fill=Match), color="black") +
  scale_x_discrete(expand = c(0, 0))+ #remove white space
  scale_y_discrete(expand = c(0, 0))+ #remove white space
  geom_text(aes(label = paste0("n=",N)), vjust = .5,  alpha = 1, size=3) +
  geom_text(aes(label = paste0("prop.=",prop)), vjust = 2.0,  alpha = 1, size=2) +
  scale_fill_manual(values = c('Match' = "#33a02c", 'No Match' = "white")) +
  theme_few() +
  theme(legend.position="none",
        axis.text.y=element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y= element_blank(),
        axis.text.x = element_text(
        angle = 45,
        hjust = 1,
        size = 8
      ))+
  labs(title="RF") +


ggplot(data = plotTableMLR,
       mapping = aes(x = Target, y = Prediction)) +
  geom_tile(aes(fill=Match), color="black") +
  scale_x_discrete(expand = c(0, 0))+ #remove white space
  scale_y_discrete(expand = c(0, 0))+ #remove white space
  geom_text(aes(label = paste0("n=",N)), vjust = .5,  alpha = 1, size=3) +
  geom_text(aes(label = paste0("prop.=",prop)), vjust = 2.0,  alpha = 1, size=2) +
  scale_fill_manual(values = c('Match' = "#33a02c", 'No Match' = "white")) +
  theme_few() +
  theme(legend.position="none",
        axis.text.y=element_blank(),
        axis.ticks.y = element_blank(),
        axis.title= element_blank(),
        axis.text.x = element_text(
        angle = 45,
        hjust = 1,
        size = 8
      ))+
  labs(title="MLR")


dev.off()
##It's SO bad! 


```


### LMER

##### Explore data prior to buidling model
```{r}
library(devtools)
install_github("dgrtwo/broom")
library(broom.mixed)
#Use tidy(modname) and augment(modname) to create a tidy dataframe of output. HALLELUJAH! 
library(lme4)
library(ggcorrplot)

colnames<-(intersect( colnames(dwl_all),  colnames(lake_descriptor))) #identify common columns 

trends_df<-dwl_all %>%
  ungroup()%>%
  inner_join(lake_descriptor, by=colnames) %>%
  inner_join(lakezones %>% select(lagoslakeid, epanutr_zoneid, neon_zoneid, wwf_zoneid), by="lagoslakeid") %>%
  filter(Trend!="No trend") %>%
  # filter(Trend %in% c("Blue -> Green",
  #                     "Green -> Blue")) %>%
  select(Hylak_id, Trend, slope, epanutr_zoneid, neon_zoneid, wwf_zoneid,early_mean) %>%
  rename(sens.slope=slope) %>%
  # mutate(Trend_simple=NA) %>%
  #   mutate(Trend_simple = replace(Trend_simple, Trend %in% c("Intensifying Blue"), 'Intensifying Blue'),
  #         Trend_simple = replace(Trend_simple, Trend %in% c("Intensifying Green/Yellow"), 'Intensifying Green/Yellow'),
  #         Trend_simple = replace(Trend_simple, Trend %in% c("Blue -> Green"), 'Blue -> Green'),
  #         Trend_simple = replace(Trend_simple, Trend %in% c("Green -> Blue"), 'Green -> Blue')) %>%
  distinct(Hylak_id,.keep_all = T) %>%
  inner_join(blue_green_2018) %>% #add LakeCat variables
  inner_join(prism_trends_wide) %>% #add PRISM variables
  inner_join(population_trends) %>% #add GLCP population variables
  inner_join(prism_trend_categories) %>%  #prism trend categories
  # select(-Trend) %>%
  # rename(Trend=Trend_simple) %>%
  # mutate(Trend = factor(
  #       Trend,
  #       levels = c(
  #         'Intensifying Blue',
  #         'Green -> Blue',
  #         'Intensifying Green/Yellow',
  #         'Blue -> Green'))) %>%
  select(-dWL, -group, -precip, -air_temp, -area)

#Tutorial here: https://ourcodingclub.github.io/2017/03/15/mixed-models.html#one

#Let's look at the vip from the RF model one more time
vip(fit_rf, geom = "col", horizontal = TRUE, size = 1.5) 

#Are any of these variables correlated with each other?
corr_alt <- trends_df %>%
  select(elev, perc_forest, perc_urban,
         slope, pop_sum, cti) %>%
  # drop_na() %>%
  cor(method="pearson")
# use the package's cor_pmat function to calculate p-values for the correlations
p.mat_alt <-  trends_df %>%
  select(elev, perc_forest, perc_urban,
         slope, pop_sum, cti) %>%
  cor_pmat()

#Create informative correlation matrix 
ggcorrplot(corr_alt, title = "Correlation matrix for lake level variables",
           lab=TRUE, 
           p.mat = p.mat_alt, sig.level = .05,
           type="upper")

#Curious about a few of these. 
trends_df %>%
  ggplot(aes(x=cv_summer_tmean_degC,y=elev, fill=slope_summer_tmean_degC))+
  geom_point(size=3,shape=21)+
  # colorspace::scale_fill_continuous_sequential(palette="ag_Sunset")+
      scale_fill_gradient(
  low = "#326cc5",
  high = "red",
  space = "Lab",
  na.value = "grey50",
  guide = "colourbar",
  aesthetics = "fill",
  name = "summer tmean\nsens slope"
)+
  theme_few()
#Here cv of summer tmean is the variation over the 1984-2020 period. So higher elevation sites tend to be more variable.
#Possibly because higher sites are warming fast? Speculative. 

trends_df %>%
  ggplot(aes(x=cv_summer_tmean_degC,y=slope, fill=elev))+
  geom_point(size=3,shape=21)+
  theme_few()+
  colorspace::scale_fill_continuous_sequential(palette="ag_Sunset")
# Given that slope and cv_summer_tmean_degC are lower down on the VIP list, I won't include those in the model.
```

##### Build model
```{r}
#First time I ran this I got a warning to scale the variables, so doing that here:
trends_df <- trends_df %>%
  mutate(elev_z=scale(elev),
         sil_z=scale(sil),
         slope_spring_tmean_degC_z=scale(slope_spring_tmean_degC),
         slope_summer_ppt_mm_z=scale(slope_summer_ppt_mm),
         cv_winter_tmean_degC_z=scale(cv_winter_tmean_degC))

# mixed.lmer <- lmer(sens.slope ~ early_mean + elev_z +  slope + slope_spring_tmean_degC_z + sil_z + slope_summer_ppt_mm_z + cv_winter_tmean_degC_z + (1|Trend), data = trends_df)
# summary(mixed.lmer)
# MuMIn::r.squaredGLMM(mixed.lmer)
# #How much variation does Trend account for?
# 0.3322/(0.3322 + 0.1067)  # ~75 %
mixed.lmer <- lmer(sens.slope ~ cti + pop_sum +  slope + perc_urban + perc_forest + (1|Trend), data = trends_df)
summary(mixed.lmer)
MuMIn::r.squaredGLMM(mixed.lmer)
#How much variation does Trend account for?
0.34799/(0.34799+0.09869)  # ~75 %

#Diagnostic plots
plot(mixed.lmer)  
qqnorm(resid(mixed.lmer))
qqline(resid(mixed.lmer)) 

library(ggeffects)  # install the package first if you haven't already, then load it

ggpredict(mixed.lmer, terms = c("perc_forest", "Trend"), type = "re") %>% 
   plot() +
   theme_minimal()

library(sjPlot)

# Visualise random effects 
(re.effects <- plot_model(mixed.lmer, type = "re", show.values = TRUE))


lm <- lm(sens.slope ~ elev_z + slope_spring_tmean_degC_z + sil_z + slope_summer_ppt_mm_z + cv_winter_tmean_degC_z, data = trends_df)
summary(lm)


mixed.lmer <- lmer(sens.slope ~ slope_summer_tmean_degC + (1|Trend), data = trends_df)
summary(mixed.lmer)
```

# ~~PCA~~

```{r, echo=FALSE, include=FALSE, message=FALSE, warning=FALSE,out.width = '100%', fig.height=4}
library(FactoMineR)
library(factoextra)
library(corrplot)
#Drop categorical variables
AllLakes_PCA<- dwl_all %>%
  ungroup() %>%
  select(Hylak_id) %>%
  inner_join(prism_trends_wide) %>% #add PRISM variables
  distinct(Hylak_id, .keep_all = TRUE) %>%
  column_to_rownames(var="Hylak_id")  #Keep some identifier for later


res.pca <- PCA(AllLakes_PCA, graph = FALSE, scale=TRUE)
eig.val <- get_eigenvalue(res.pca)
#An eigenvalue > 1 indicates that PCs account for more variance than accounted by one of the original variables in standardized data. This is commonly used as a cutoff point for which PCs are retained. This holds true only when the data are standardized.

#Another method for seeing how many PCs is enough
fviz_eig(res.pca, addlabels = TRUE)

# This function provides a list of matrices containing all the results for the active variables (coordinates, correlation between variables and axes, squared cosine and contributions)
var <- get_pca_var(res.pca)

head(var$coord, 10)
fviz_pca_var(res.pca, col.var = "black")
#Interpretation:
#- Positively correlated variables are grouped together.
#- Negatively correlated variables are positioned on opposite sides of the plot origin (opposed quadrants).
#- The distance between variables and the origin measures the quality of the variables on the factor map. Variables that are away from the origin are well represented on the factor map.


head(var$contrib, 10)


corrplot(var$cos2, is.corr=FALSE)
corrplot(var$coord, is.corr=TRUE)

#Plot just the first 2 PCs
var_trim<-var$coord[,1:2]
corrplot(var_trim,
         mar = c(4,0,4,0), tl.srt=45,
                  cl.ratio=2, cl.align="l",
          number.digits = 1,
         cl.lim=c(-1,1))

#The quality of representation of the variables on factor map is called cos2 (square cosine, squared coordinates) 
# Color by cos2 values: quality on the factor map
# Contributions of variables to PC1
fviz_contrib(res.pca, choice = "var", axes = 1, top = 10)
# Contributions of variables to PC2
fviz_contrib(res.pca, choice = "var", axes = 2, top = 10)
#The red dashed line on the graph above indicates the expected average contribution. If the contribution of the variables were uniform, the expected value would be 1/length(variables) = 1/10 = 10%. For a given component, a variable with a contribution larger than this cutoff could be considered as important in contributing to the component.
fviz_contrib(res.pca, choice = "var", axes = 3, top = 10)

fviz_pca_var(res.pca, col.var = "cos2",
             # alpha.var = "contrib"
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE # Avoid text overlapping
             )

#Contributions of variables to PCs
head(var$contrib, 4)
#Highlighted in a plot
fviz_pca_var(res.pca, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07")
             )

#Dimension description
res.desc <- dimdesc(res.pca, axes = c(1,2,3), proba = 0.05)
# Description of dimension 1
res.desc$Dim.1
# Description of dimension 2
res.desc$Dim.2
# Description of dimension3
res.desc$Dim.3


##Extract Dim.1 and Dim.2 variables, combine to DF, and look at correlations with predictors
Dim_1_2<-as.data.frame(res.pca$ind$coord) %>%
  dplyr::select(Dim.1, Dim.2) %>%
  tibble::rownames_to_column("Hylak_id")

dim1_corr<-res.desc$call$X %>%
    tibble::rownames_to_column("Hylak_id")

PCAdf<-left_join(dim1_corr,Dim_1_2, by=c("Hylak_id","Dim.1")) %>%
  left_join(., dwl_all %>%
              ungroup()%>%
              select(Hylak_id, Trend) %>%
              mutate(Hylak_id = as.character(as.numeric(Hylak_id))), by="Hylak_id") %>%
  mutate_if(is.numeric, scale) #scale all numeric values
```

```{r, echo=FALSE, message=FALSE, warning=FALSE,out.width = '100%', fig.height=4}
library(ggpubr)
########################################
#Biplot with individual points - color by burn_YN
########################################

pca <- PCA(AllLakes_PCA, graph = FALSE, scale=TRUE) #use the full df


########################################
#Biplot with individual points - color by lake
########################################




trendColors <- c(
  'No trend' = 'grey90',
  'Intensifying Blue' = '#1f78b4',
  'Green -> Blue' = '#a6cee3',
  'Intensifying Green/Yellow' = '#33a02c',
  'Blue -> Green' = '#b2df8a'
)


fviz_pca_biplot(pca,
                # col.ind = AllLakes$burn_YN,
                palette = trendColors,
                geom.ind = c("none"), # show points only (nbut not "text")
                addEllipses = TRUE,
                label = "var",
                alpha.ind=0.8,
                alpha.var=0.7,
                point.size=3,
                labelsize=5,
                col.var = "black",
                repel = TRUE,
                ggtheme = theme_pubr(),
                mean.point=FALSE,
                legend.position="none",
                legend.title = "Trend groupings",
                title="") +
    scale_shape_manual(values=c(22,21,20,24,25))+
  geom_point(data=PCAdf,
             aes(x=Dim.1, y=Dim.2,
                color=Trend, fill=Trend, shape=Trend),
                size=2, alpha=0.6, color="black")+
  scale_fill_manual(values=trendColors)+
  scale_color_manual(values=trendColors)+
  theme(plot.title = element_text(margin = margin(b = 5), size = 13),
  panel.spacing=grid::unit(0,"lines"))

```


#~*~* Explore trends
```{r}
head(trends_df)

explore <- dwl_all %>%
  ungroup()%>%
  # filter(Trend!="No trend") %>%
  # filter(Trend %in% c("Blue -> Green",
  #                     "Green -> Blue")) %>%
  select(Hylak_id, Trend, slope) %>%
  rename(sens.slope=slope) %>%
  # mutate(Trend_simple=NA) %>%
  # mutate(Trend_simple = replace(Trend_simple, Trend %in% c("Intensifying Blue","Green -> Blue"), 'Bluer'),
  #        Trend_simple = replace(Trend_simple, Trend %in% c("Intensifying Green/Yellow","Blue -> Green"), 'Greener')) %>%
  distinct(Hylak_id,.keep_all = T) %>%
  inner_join(blue_green_2018) %>% #add LakeCat variables
  inner_join(prism_trends_wide) %>% #add PRISM variables
  inner_join(population_trends) %>% #add GLCP population variables
  inner_join(prism_trend_categories) #prism trend categories
  # select(-c(air_temp,precip,pop_sum)) %>%
  # select(-c(contains(c("perc_","cv_"))))
# head(explore)
str(explore)

explore %>%
  ggplot(aes(x=slope,y=population_change,fill=Trend))+
  geom_point(shape=21)+
  scale_fill_manual(values=trendColors)+
  geom_hline(yintercept=-94) #the cutoff for trending blue in one of CART model runs


#First tree node -- if winter ppt is not changing, the lake is greening (about 6 sites)
# But if the slope of winter ppt is between -0.055 to 0.34, lake most likely getting blue
explore %>%
  ggplot(aes(x=slope,y=slope_winter_ppt_mm,fill=Trend))+
  geom_point(shape=21)+
  scale_fill_manual(values=trendColors)+
  geom_hline(yintercept=0.335)+ #the cutoff for trending blue in one of CART model runs
  geom_hline(yintercept=-0.055) #the cutoff for trending blue in one of CART model runs

#First tree node -- if winter ppt is increasing, and summer temperature is NOT increasing
#Then lake most likely intensifying blue
explore %>%
  filter(elev<2617.32) %>%
  filter(Trend!="No trend") %>%
  ggplot(aes(x=slope_summer_tmean_degC,y=slope_spring_ppt_mm,fill=Trend))+
  geom_point(shape=21,size=3)+
  scale_fill_manual(values=trendColors)+
  geom_hline(yintercept=0.06)+ 
  geom_vline(xintercept=0.035) 

explore %>%
  filter(elev<2617.32) %>%
  filter(Trend!="No trend") %>%
  ggplot(aes(x=elev,y=perc_barren,fill=Trend))+
  geom_point(shape=21,size=3)+
  scale_fill_manual(values=trendColors)+
  geom_hline(yintercept=0.06)+ 
  geom_vline(xintercept=0.035) 

##Code borrowed from Simon Topp's 2021 ERL paper
#Look at the distribution of clarity change across in-network and out-of-network lakes, no
ggplot(explore, aes(x = sens.slope)) +
  geom_density(alpha = .4, aes(fill = factor(Trend)))+
    scale_fill_manual(values=trendColors)

ggplot(explore %>%
           filter(Trend!="No trend"), aes(x = elev, color=Trend)) +
  # geom_histogram(aes(x=elev, y = ..density.., fill=Trend),
  #                color = 'black',bins = 50) + 
  # geom_density(aes(x=elev)) + 
  geom_freqpoly(bins = 20, size = 1) + 
  scale_color_manual(values=trendColors)+
  facet_wrap(~Trend,nrow=4,scales="free_y")+
  geom_vline(xintercept=2617.32)+
  theme(legend.position="none")


explore %>%
  select(Hylak_id, Trend, sens.slope, slope, n_dep, WALA, LSA, ws_area) %>%
  pivot_longer(-c(1:3)) %>%
  # filter(name=="n_dep") %>%
  ggplot(aes(x = value)) +
  geom_density(alpha = .4, aes(fill = factor(Trend)))+
  scale_fill_manual(values=trendColors)+
  facet_wrap(name~., scales="free")

hist(explore$n_dep)

###################################################
# Look at reservoirs vs natural lakes
###################################################
ggplot(explore, aes(x = res, y = sens.slope, group = res))  +
  geom_violin() + 
  geom_boxplot(width = .1, fill = 'grey60') +
  geom_hline(yintercept = 0, color = 'red') +
  facet_wrap(~Trend)+
  # scale_fill_viridis_c('Number of\nLakes', option = 'plasma', end = .8, trans = 'log10') +
  # coord_cartesian(ylim = c(-5,5))+
  labs(x = 'Lake Type', y = 'Slope Distribution (dwl/year)', title = 'Slope Distribution by lake Type') +
  theme_few()

#No differences
wilcox.test(explore$sens.slope[explore$res == 'NL' & explore$Trend == 'Intensifying Green/Yellow'],
            explore$sens.slope[explore$res == 'RSVR' & explore$Trend == 'Intensifying Green/Yellow'], conf.int = T)
wilcox.test(explore$sens.slope[explore$res == 'NL' & explore$Trend == 'Intensifying Blue'],
            explore$sens.slope[explore$res == 'RSVR' & explore$Trend == 'Intensifying Blue'], conf.int = T)


ggplot(explore, aes(x = temp_trend_summer, y = sens.slope, group = temp_trend_summer))  +
  geom_violin() + 
  geom_boxplot(width = .1, fill = 'grey60') +
  geom_hline(yintercept = 0, color = 'red') +
  facet_wrap(~Trend)+
  # scale_fill_viridis_c('Number of\nLakes', option = 'plasma', end = .8, trans = 'log10') +
  # coord_cartesian(ylim = c(-5,5))+
  labs(x = 'Lake Type', y = 'Slope Distribution (dwl/year)', title = 'Slope Distribution by lake Type') +
  theme_few()

wilcox.test(explore$sens.slope[explore$temp_trend_summer == 'No trend' & explore$Trend == 'Intensifying Blue'],
            explore$sens.slope[explore$temp_trend_summer == 'warmer' & explore$Trend == 'Intensifying Blue'], conf.int = T)
#There are some differences but honestly kind of hard to interpret. In areas with warming summer, the intensifying blue slope is lower?

explore %>%
  mutate(Size.Group = cut(area, breaks = c(0,1,10,100,2000), labels = c('<1','1-10','10-100','>100'))) %>%
  ggplot(aes(x = Size.Group, y = abs(sens.slope), group = Size.Group, fill=Trend))  +
  # geom_violin() + 
  geom_jitter(shape=21, alpha=0.9, width=0.2) +
  geom_boxplot(width = .1, outlier.shape=NA) +
  geom_hline(yintercept = 0, color = 'red') +
  facet_wrap(~Trend, ncol=5, scales="free_y")+
  scale_fill_manual(values=trendColors)+
  labs(x = 'Lake Type', y = 'Slope Distribution (dwl/year)', title = 'Slope Distribution by lake Type') +
  theme_few()

#Within each trend category, RSVRs have steeper slopes than natural lakes
explore %>%
  ggplot(aes(x = res, y = sens.slope, group = res, fill=Trend))  +
  # geom_violin() + 
  geom_boxplot(width = .3, outlier.shape=NA) +
    geom_jitter(shape=21, alpha=0.9, width=0.2) +
  geom_hline(yintercept = 0, color = 'red') +
  facet_wrap(~Trend, ncol=5, scales="free_y")+
  scale_fill_manual(values=trendColors)+
  labs(x = 'Lake Type', y = 'Slope Distribution (dwl/year)', title = 'Slope Distribution by lake Type') +
  theme_few()

explore %>%
  ggplot(aes(x = temp_trend_summer, y = slope_summer_tmean_degC, group = temp_trend_summer, fill=Trend))  +
  # geom_violin() + 
  geom_jitter(shape=21, alpha=0.9, width=0.2) +
  geom_boxplot(width = .1, outlier.shape=NA) +
  geom_hline(yintercept = 0, color = 'red') +
  facet_wrap(~Trend, ncol=5)+
  scale_fill_manual(values=trendColors)+
  labs(x = 'Lake Type', y = 'Summer Temp Slope Distribution (deg C/year)', title = 'Slope Distribution by lake Type',
       subtitle='In all trend categories, there are a sizable number of lakes that experience summer warming') +
  theme_few()

explore %>%
  ggplot(aes(x = temp_trend_summer, y = sens.slope, group = temp_trend_summer, fill=Trend))  +
  # geom_violin() + 
  geom_jitter(shape=21, alpha=0.9, width=0.2) +
  geom_boxplot(width = .1, outlier.shape=NA) +
  geom_hline(yintercept = 0, color = 'red') +
  facet_wrap(~Trend, ncol=5)+
  scale_fill_manual(values=trendColors)+
  labs(x = 'Summer warming?', y = 'Slope Distribution (dwl/year)', title = 'Slope Distribution by lake Type',
       subtitle="But the slope of the color change isn't different between lakes experiencing summer warming or not") +
  theme_few()

explore %>%
  ggplot(aes(x = ppt_trend_winter, y = sens.slope, group = ppt_trend_winter, fill=Trend))  +
  # geom_violin() + 
  geom_jitter(shape=21, alpha=0.9, width=0.2) +
  geom_boxplot(width = .1, outlier.shape=NA) +
  geom_hline(yintercept = 0, color = 'red') +
  facet_wrap(~Trend, ncol=5)+
  scale_fill_manual(values=trendColors)+
  labs(x = 'Winter wetter?', y = 'Slope Distribution (dwl/year)', title = 'Slope Distribution by lake Type',
       subtitle="But the slope of the color change isn't different between lakes experiencing summer warming or not") +
  theme_few()


  ggplot(trends_df, aes(x = Trend, y = cv_winter_tmean_degC, fill = Trend)) +
  # geom_violin()+
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(
    aes(fill = Trend),
    shape = 21,
    size = 0.5,
    alpha = 0.6,
    position = position_jitter(0.2)
  ) +
  # geom_hline(yintercept = med_noTrend, linetype = "dashed") +
  scale_fill_manual(values = trendColors) +
  guides(fill = "none") +
  theme_few() +
  theme(
    axis.text.x = element_blank(),
    axis.title.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  labs(y = "Watershed slope")

```

##** MISC**
Export data for Sam Sillen
```{r,eval=F}
head(dwl_all)

colnames<-(intersect( colnames(dwl_all),  colnames(lake_descriptor))) #identify common columns between data.tables


export <- dwl_all %>%
  ungroup()%>%
  inner_join(lake_descriptor, by=colnames) %>%
  select(Hylak_id, comid, gnis_id, gnis_name, lagoslakeid, lake_lat_decdeg, lake_lon_decdeg, elevation, lake_centroidstate,
         year, value, slope, intercept, Trend) %>%
  rename(dWL=value) %>%
  filter(Trend!="No trend")
write_csv(export,'data/export/lake_color_changing.csv')

length(unique(export$Hylak_id))
```